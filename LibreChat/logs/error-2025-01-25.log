{"level":"error","message":"KeyvMongo connection error: connect ECONNREFUSED 172.20.0.4:27017","reason":{"commonWireVersion":0,"compatible":true,"heartbeatFrequencyMS":10000,"localThresholdMS":15,"logicalSessionTimeoutMinutes":null,"maxElectionId":null,"maxSetVersion":null,"servers":{},"setName":null,"stale":false,"type":"Unknown"},"stack":"MongoServerSelectionError: connect ECONNREFUSED 172.20.0.4:27017\n    at Timeout._onTimeout (/app/node_modules/@keyv/mongo/node_modules/mongodb/lib/sdam/topology.js:292:38)\n    at listOnTimeout (node:internal/timers:581:17)\n    at process.processTimers (node:internal/timers:519:7)"}
{"code":"ENOENT","errno":-2,"level":"error","message":"Config file YAML format is invalid: ENOENT: no such file or directory, open '/app/librechat.yaml'","path":"/app/librechat.yaml","stack":"Error: ENOENT: no such file or directory, open '/app/librechat.yaml'\n    at Object.readFileSync (node:fs:448:20)\n    at loadYaml (/app/api/utils/loadYaml.js:6:27)\n    at loadCustomConfig (/app/api/server/services/Config/loadCustomConfig.js:36:20)\n    at AppService (/app/api/server/services/AppService.js:25:25)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async startServer (/app/api/server/index.js:40:3)","syscall":"open"}
{"code":"ENOENT","errno":-2,"level":"error","message":"Config file YAML format is invalid: ENOENT: no such file or directory, open '/app/librechat.yaml'","path":"/app/librechat.yaml","stack":"Error: ENOENT: no such file or directory, open '/app/librechat.yaml'\n    at Object.readFileSync (node:fs:448:20)\n    at loadYaml (/app/api/utils/loadYaml.js:6:27)\n    at loadCustomConfig (/app/api/server/services/Config/loadCustomConfig.js:36:20)\n    at AppService (/app/api/server/services/AppService.js:25:25)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async startServer (/app/api/server/index.js:40:3)","syscall":"open"}
{"code":"ENOENT","errno":-2,"level":"error","message":"Config file YAML format is invalid: ENOENT: no such file or directory, open '/app/librechat.yaml'","path":"/app/librechat.yaml","stack":"Error: ENOENT: no such file or directory, open '/app/librechat.yaml'\n    at Object.readFileSync (node:fs:448:20)\n    at loadYaml (/app/api/utils/loadYaml.js:6:27)\n    at loadCustomConfig (/app/api/server/services/Config/loadCustomConfig.js:36:20)\n    at AppService (/app/api/server/services/AppService.js:25:25)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async startServer (/app/api/server/index.js:40:3)","syscall":"open"}
{"code":"ENOENT","errno":-2,"level":"error","message":"Config file YAML format is invalid: ENOENT: no such file or directory, open '/app/librechat.yaml'","path":"/app/librechat.yaml","stack":"Error: ENOENT: no such file or directory, open '/app/librechat.yaml'\n    at Object.readFileSync (node:fs:448:20)\n    at loadYaml (/app/api/utils/loadYaml.js:6:27)\n    at loadCustomConfig (/app/api/server/services/Config/loadCustomConfig.js:36:20)\n    at AppService (/app/api/server/services/AppService.js:25:25)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async startServer (/app/api/server/index.js:40:3)","syscall":"open"}
{"code":"ENOENT","errno":-2,"level":"error","message":"Config file YAML format is invalid: ENOENT: no such file or directory, open '/app/librechat.yaml'","path":"/app/librechat.yaml","stack":"Error: ENOENT: no such file or directory, open '/app/librechat.yaml'\n    at Object.readFileSync (node:fs:448:20)\n    at loadYaml (/app/api/utils/loadYaml.js:6:27)\n    at loadCustomConfig (/app/api/server/services/Config/loadCustomConfig.js:36:20)\n    at AppService (/app/api/server/services/AppService.js:25:25)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async startServer (/app/api/server/index.js:40:3)","syscall":"open"}
{"level":"error","mark":{"buffer":"# For more information, see the Configuration Guide:\r\n# https://www.librechat.ai/docs/configuration/librechat_yaml\r\n\r\n# Configuration version (required)\r\nversion: 1.2.1\r\n\r\n# Cache settings: Set to true to enable caching\r\ncache: true\r\n\r\n# Custom interface configuration\r\ninterface:\r\n  # Privacy policy settings\r\n  privacyPolicy:\r\n    externalUrl: 'https://librechat.ai/privacy-policy'\r\n    openNewTab: true\r\n\r\n  # Terms of service\r\n  termsOfService:\r\n    externalUrl: 'https://librechat.ai/tos'\r\n    openNewTab: true\r\n    modalAcceptance: true\r\n    modalTitle: \"Terms of Service for LibreChat\"\r\n    modalContent: |\r\n      # Terms and Conditions for LibreChat\r\n\r\n      *Effective Date: February 18, 2024*\r\n\r\n      Welcome to LibreChat, the informational website for the open-source AI chat platform, available at https://librechat.ai. These Terms of Service (\"Terms\") govern your use of our website and the services we offer. By accessing or using the Website, you agree to be bound by these Terms and our Privacy Policy, accessible at https://librechat.ai//privacy.\r\n\r\n      ## 1. Ownership\r\n\r\n      Upon purchasing a package from LibreChat, you are granted the right to download and use the code for accessing an admin panel for LibreChat. While you own the downloaded code, you are expressly prohibited from reselling, redistributing, or otherwise transferring the code to third parties without explicit permission from LibreChat.\r\n\r\n      ## 2. User Data\r\n\r\n      We collect personal data, such as your name, email address, and payment information, as described in our Privacy Policy. This information is collected to provide and improve our services, process transactions, and communicate with you.\r\n\r\n      ## 3. Non-Personal Data Collection\r\n\r\n      The Website uses cookies to enhance user experience, analyze site usage, and facilitate certain functionalities. By using the Website, you consent to the use of cookies in accordance with our Privacy Policy.\r\n\r\n      ## 4. Use of the Website\r\n\r\n      You agree to use the Website only for lawful purposes and in a manner that does not infringe the rights of, restrict, or inhibit anyone else's use and enjoyment of the Website. Prohibited behavior includes harassing or causing distress or inconvenience to any person, transmitting obscene or offensive content, or disrupting the normal flow of dialogue within the Website.\r\n\r\n      ## 5. Governing Law\r\n\r\n      These Terms shall be governed by and construed in accordance with the laws of the United States, without giving effect to any principles of conflicts of law.\r\n\r\n      ## 6. Changes to the Terms\r\n\r\n      We reserve the right to modify these Terms at any time. We will notify users of any changes by email. Your continued use of the Website after such changes have been notified will constitute your consent to such changes.\r\n\r\n      ## 7. Contact Information\r\n\r\n      If you have any questions about these Terms, please contact us at contact@librechat.ai.\r\n\r\n      By using the Website, you acknowledge that you have read these Terms of Service and agree to be bound by them.\r\n\r\n  endpointsMenu: true\r\n  modelSelect: true\r\n  parameters: true\r\n  sidePanel: true\r\n  presets: true\r\n  prompts: true\r\n  bookmarks: true\r\n  multiConvo: true\r\n  agents: true\r\n\r\n# Example Registration Object Structure (optional)\r\nregistration:\r\n  socialLogins: ['github', 'google', 'discord', 'openid', 'facebook']\r\n  # allowedDomains:\r\n  # - \"gmail.com\"\r\n\r\n# speech:\r\n#   tts:\r\n#     openai:\r\n#       url: ''\r\n#       apiKey: '${TTS_API_KEY}'\r\n#       model: ''\r\n#       voices: ['']\r\n\r\n#  \r\n#   stt:\r\n#     openai:\r\n#       url: ''\r\n#       apiKey: '${STT_API_KEY}'\r\n#       model: ''\r\n\r\n# rateLimits:\r\n#   fileUploads:\r\n#     ipMax: 100\r\n#     ipWindowInMinutes: 60  # Rate limit window for file uploads per IP\r\n#     userMax: 50\r\n#     userWindowInMinutes: 60  # Rate limit window for file uploads per user\r\n#   conversationsImport:\r\n#     ipMax: 100\r\n#     ipWindowInMinutes: 60  # Rate limit window for conversation imports per IP\r\n#     userMax: 50\r\n#     userWindowInMinutes: 60  # Rate limit window for conversation imports per user\r\n\r\n# Example Actions Object Structure\r\nactions:\r\n  allowedDomains:\r\n    - \"swapi.dev\"\r\n    - \"librechat.ai\"\r\n    - \"google.com\"\r\n\r\n# Example MCP Servers Object Structure\r\nmcpServers:\r\n  everything:\r\n    # type: sse # type can optionally be omitted\r\n    url: http://localhost:3001/sse\r\n  puppeteer:\r\n    type: stdio\r\n    command: npx\r\n    args:\r\n      - -y\r\n      - \"@modelcontextprotocol/server-puppeteer\"\r\n  filesystem:\r\n    # type: stdio\r\n    command: npx\r\n    args:\r\n      - -y\r\n      - \"@modelcontextprotocol/server-filesystem\"\r\n      - /home/user/LibreChat/\r\n    iconPath: /home/user/LibreChat/client/public/assets/logo.svg\r\n  mcp-obsidian:\r\n    command: npx\r\n    args:\r\n      - -y\r\n      - \"mcp-obsidian\"\r\n      - /path/to/obsidian/vault\r\n\r\n# Definition of custom endpoints\r\nendpoints:\r\n  # assistants:\r\n  #   disableBuilder: false # Disable Assistants Builder Interface by setting to `true`\r\n  #   pollIntervalMs: 3000  # Polling interval for checking assistant updates\r\n  #   timeoutMs: 180000  # Timeout for assistant operations\r\n  #   # Should only be one or the other, either `supportedIds` or `excludedIds`\r\n  #   supportedIds: [\"asst_supportedAssistantId1\", \"asst_supportedAssistantId2\"]\r\n  #   # excludedIds: [\"asst_excludedAssistantId\"]\r\n  #   Only show assistants that the user created or that were created externally (e.g. in Assistants playground).\r\n  #   # privateAssistants: false # Does not work with `supportedIds` or `excludedIds`\r\n  #   # (optional) Models that support retrieval, will default to latest known OpenAI models that support the feature\r\n  #   retrievalModels: [\"gpt-4-turbo-preview\"]\r\n  #   # (optional) Assistant Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.\r\n  #   capabilities: [\"code_interpreter\", \"retrieval\", \"actions\", \"tools\", \"image_vision\"]\r\n  agents:\r\n    (optional) Maximum recursion depth for agents, defaults to 25\r\n    recursionLimit: 50\r\n    (optional) Disable the builder interface for agents\r\n    disableBuilder: false\r\n    (optional) Agent Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.\r\n    capabilities: []\r\n  custom:\r\n    # Groq Example\r\n    - name: 'groq'\r\n      apiKey: '${GROQ_API_KEY}'\r\n      baseURL: 'https://api.groq.com/openai/v1/'\r\n      models:\r\n        default:\r\n          [\r\n            'llama3-70b-8192',\r\n            'llama3-8b-8192',\r\n            'llama2-70b-4096',\r\n            'mixtral-8x7b-32768',\r\n            'gemma-7b-it',\r\n          ]\r\n        fetch: false\r\n      titleConvo: true\r\n      titleModel: 'mixtral-8x7b-32768'\r\n      modelDisplayLabel: 'groq'\r\n\r\n    # Mistral AI Example\r\n    - name: 'Mistral' # Unique name for the endpoint\r\n      # For `apiKey` and `baseURL`, you can use environment variables that you define.\r\n      # recommended environment variables:\r\n      apiKey: '${MISTRAL_API_KEY}'\r\n      baseURL: 'https://api.mistral.ai/v1'\r\n\r\n      # Models configuration\r\n      models:\r\n        # List of default models to use. At least one value is required.\r\n        default: ['mistral-tiny', 'mistral-small', 'mistral-medium']\r\n        # Fetch option: Set to true to fetch models from API.\r\n        fetch: true # Defaults to false.\r\n\r\n      # Optional configurations\r\n\r\n      # Title Conversation setting\r\n      titleConvo: true # Set to true to enable title conversation\r\n\r\n      # Title Method: Choose between \"completion\" or \"functions\".\r\n      # titleMethod: \"completion\"  # Defaults to \"completion\" if omitted.\r\n\r\n      # Title Model: Specify the model to use for titles.\r\n      titleModel: 'mistral-tiny' # Defaults to \"gpt-3.5-turbo\" if omitted.\r\n\r\n      # Summarize setting: Set to true to enable summarization.\r\n      # summarize: false\r\n\r\n      # Summary Model: Specify the model to use if summarization is enabled.\r\n      # summaryModel: \"mistral-tiny\"  # Defaults to \"gpt-3.5-turbo\" if omitted.\r\n\r\n      # Force Prompt setting: If true, sends a `prompt` parameter instead of `messages`.\r\n      # forcePrompt: false\r\n\r\n      # The label displayed for the AI model in messages.\r\n      modelDisplayLabel: 'Mistral' # Default is \"AI\" when not set.\r\n\r\n      # Add additional parameters to the request. Default params will be overwritten.\r\n      # addParams:\r\n      # safe_prompt: true # This field is specific to Mistral AI: https://docs.mistral.ai/api/\r\n\r\n      # Drop Default params parameters from the request. See default params in guide linked below.\r\n      # NOTE: For Mistral, it is necessary to drop the following parameters or you will encounter a 422 Error:\r\n      dropParams: ['stop', 'user', 'frequency_penalty', 'presence_penalty']\r\n\r\n    # OpenRouter Example\r\n    - name: 'OpenRouter'\r\n      # For `apiKey` and `baseURL`, you can use environment variables that you define.\r\n      # recommended environment variables:\r\n      # Known issue: you should not use `OPENROUTER_API_KEY` as it will then override the `openAI` endpoint to use OpenRouter as well.\r\n      apiKey: '${OPENROUTER_KEY}'\r\n      baseURL: 'https://openrouter.ai/api/v1'\r\n      models:\r\n        default: ['meta-llama/llama-3-70b-instruct']\r\n        fetch: true\r\n      titleConvo: true\r\n      titleModel: 'meta-llama/llama-3-70b-instruct'\r\n      # Recommended: Drop the stop parameter from the request as Openrouter models use a variety of stop tokens.\r\n      dropParams: ['stop']\r\n      modelDisplayLabel: 'OpenRouter'\r\n      \r\n    # Portkey AI Example\r\n    - name: \"Portkey\"\r\n      apiKey: \"dummy\"  \r\n      baseURL: 'https://api.portkey.ai/v1'\r\n      headers:\r\n          x-portkey-api-key: [REDACTED]          x-portkey-virtual-key: '${PORTKEY_OPENAI_VIRTUAL_KEY}'\r\n      models:\r\n          default: ['gpt-4o-mini', 'gpt-4o', 'chatgpt-4o-latest']\r\n          fetch: true\r\n      titleConvo: true\r\n      titleModel: 'current_model'\r\n      summarize: false\r\n      summaryModel: 'current_model'\r\n      forcePrompt: false\r\n      modelDisplayLabel: 'Portkey'\r\n      iconURL: https://images.crunchbase.com/image/upload/c_pad,f_auto,q_auto:eco,dpr_1/rjqy7ghvjoiu4cd1xjbf\r\n# fileConfig:\r\n#   endpoints:\r\n#     assistants:\r\n#       fileLimit: 5\r\n#       fileSizeLimit: 10  # Maximum size for an individual file in MB\r\n#       totalSizeLimit: 50  # Maximum total size for all files in a single request in MB\r\n#       supportedMimeTypes:\r\n#         - \"image/.*\"\r\n#         - \"application/pdf\"\r\n#     openAI:\r\n#       disabled: true  # Disables file uploading to the OpenAI endpoint\r\n#     default:\r\n#       totalSizeLimit: 20\r\n#     YourCustomEndpointName:\r\n#       fileLimit: 2\r\n#       fileSizeLimit: 5\r\n#   serverFileSizeLimit: 100  # Global server file size limit in MB\r\n#   avatarSizeLimit: 2  # Limit for user avatar image size in MB\r\n# See the Custom Configuration Guide for more information on Assistants Config:\r\n# https://www.librechat.ai/docs/configuration/librechat_yaml/object_structure/assistants_endpoint\r\n","column":18,"line":152,"name":null,"position":6068,"snippet":" 150 |   #   capabilities: [\"code_interpreter\", \"retriev ...\n 151 |   agents:\n 152 |     (optional) Maximum recursion depth for agents ...\n 153 |     recursionLimit: 50\n-------------------------^\n 154 |     (optional) Disable the builder interface for  ...\n 155 |     disableBuilder: false"},"message":"Config file YAML format is invalid: bad indentation of a mapping entry (153:19)\n\n 150 |   #   capabilities: [\"code_interpreter\", \"retriev ...\n 151 |   agents:\n 152 |     (optional) Maximum recursion depth for agents ...\n 153 |     recursionLimit: 50\n-------------------------^\n 154 |     (optional) Disable the builder interface for  ...\n 155 |     disableBuilder: false","name":"YAMLException","reason":"bad indentation of a mapping entry","stack":"YAMLException: bad indentation of a mapping entry (153:19)\n\n 150 |   #   capabilities: [\"code_interpreter\", \"retriev ...\n 151 |   agents:\n 152 |     (optional) Maximum recursion depth for agents ...\n 153 |     recursionLimit: 50\n-------------------------^\n 154 |     (optional) Disable the builder interface for  ...\n 155 |     disableBuilder: false\n    at generateError (/app/node_modules/js-yaml/lib/loader.js:183:10)\n    at throwError (/app/node_modules/js-yaml/lib/loader.js:187:9)\n    at readBlockMapping (/app/node_modules/js-yaml/lib/loader.js:1182:7)\n    at composeNode (/app/node_modules/js-yaml/lib/loader.js:1441:12)\n    at readBlockMapping (/app/node_modules/js-yaml/lib/loader.js:1164:11)\n    at composeNode (/app/node_modules/js-yaml/lib/loader.js:1441:12)\n    at readDocument (/app/node_modules/js-yaml/lib/loader.js:1625:3)\n    at loadDocuments (/app/node_modules/js-yaml/lib/loader.js:1688:5)\n    at Object.load (/app/node_modules/js-yaml/lib/loader.js:1714:19)\n    at loadYaml (/app/api/utils/loadYaml.js:7:17)"}
{"level":"error","mark":{"buffer":"# For more information, see the Configuration Guide:\r\n# https://www.librechat.ai/docs/configuration/librechat_yaml\r\n\r\n# Configuration version (required)\r\nversion: 1.2.1\r\n\r\n# Cache settings: Set to true to enable caching\r\ncache: true\r\n\r\n# Custom interface configuration\r\ninterface:\r\n  # Privacy policy settings\r\n  privacyPolicy:\r\n    externalUrl: 'https://librechat.ai/privacy-policy'\r\n    openNewTab: true\r\n\r\n  # Terms of service\r\n  termsOfService:\r\n    externalUrl: 'https://librechat.ai/tos'\r\n    openNewTab: true\r\n    modalAcceptance: true\r\n    modalTitle: \"Terms of Service for LibreChat\"\r\n    modalContent: |\r\n      # Terms and Conditions for LibreChat\r\n\r\n      *Effective Date: February 18, 2024*\r\n\r\n      Welcome to LibreChat, the informational website for the open-source AI chat platform, available at https://librechat.ai. These Terms of Service (\"Terms\") govern your use of our website and the services we offer. By accessing or using the Website, you agree to be bound by these Terms and our Privacy Policy, accessible at https://librechat.ai//privacy.\r\n\r\n      ## 1. Ownership\r\n\r\n      Upon purchasing a package from LibreChat, you are granted the right to download and use the code for accessing an admin panel for LibreChat. While you own the downloaded code, you are expressly prohibited from reselling, redistributing, or otherwise transferring the code to third parties without explicit permission from LibreChat.\r\n\r\n      ## 2. User Data\r\n\r\n      We collect personal data, such as your name, email address, and payment information, as described in our Privacy Policy. This information is collected to provide and improve our services, process transactions, and communicate with you.\r\n\r\n      ## 3. Non-Personal Data Collection\r\n\r\n      The Website uses cookies to enhance user experience, analyze site usage, and facilitate certain functionalities. By using the Website, you consent to the use of cookies in accordance with our Privacy Policy.\r\n\r\n      ## 4. Use of the Website\r\n\r\n      You agree to use the Website only for lawful purposes and in a manner that does not infringe the rights of, restrict, or inhibit anyone else's use and enjoyment of the Website. Prohibited behavior includes harassing or causing distress or inconvenience to any person, transmitting obscene or offensive content, or disrupting the normal flow of dialogue within the Website.\r\n\r\n      ## 5. Governing Law\r\n\r\n      These Terms shall be governed by and construed in accordance with the laws of the United States, without giving effect to any principles of conflicts of law.\r\n\r\n      ## 6. Changes to the Terms\r\n\r\n      We reserve the right to modify these Terms at any time. We will notify users of any changes by email. Your continued use of the Website after such changes have been notified will constitute your consent to such changes.\r\n\r\n      ## 7. Contact Information\r\n\r\n      If you have any questions about these Terms, please contact us at contact@librechat.ai.\r\n\r\n      By using the Website, you acknowledge that you have read these Terms of Service and agree to be bound by them.\r\n\r\n  endpointsMenu: true\r\n  modelSelect: true\r\n  parameters: true\r\n  sidePanel: true\r\n  presets: true\r\n  prompts: true\r\n  bookmarks: true\r\n  multiConvo: true\r\n  agents: true\r\n\r\n# Example Registration Object Structure (optional)\r\nregistration:\r\n  socialLogins: ['github', 'google', 'discord', 'openid', 'facebook']\r\n  # allowedDomains:\r\n  # - \"gmail.com\"\r\n\r\n# speech:\r\n#   tts:\r\n#     openai:\r\n#       url: ''\r\n#       apiKey: '${TTS_API_KEY}'\r\n#       model: ''\r\n#       voices: ['']\r\n\r\n#  \r\n#   stt:\r\n#     openai:\r\n#       url: ''\r\n#       apiKey: '${STT_API_KEY}'\r\n#       model: ''\r\n\r\n# rateLimits:\r\n#   fileUploads:\r\n#     ipMax: 100\r\n#     ipWindowInMinutes: 60  # Rate limit window for file uploads per IP\r\n#     userMax: 50\r\n#     userWindowInMinutes: 60  # Rate limit window for file uploads per user\r\n#   conversationsImport:\r\n#     ipMax: 100\r\n#     ipWindowInMinutes: 60  # Rate limit window for conversation imports per IP\r\n#     userMax: 50\r\n#     userWindowInMinutes: 60  # Rate limit window for conversation imports per user\r\n\r\n# Example Actions Object Structure\r\nactions:\r\n  allowedDomains:\r\n    - \"swapi.dev\"\r\n    - \"librechat.ai\"\r\n    - \"google.com\"\r\n\r\n# Example MCP Servers Object Structure\r\nmcpServers:\r\n  everything:\r\n    # type: sse # type can optionally be omitted\r\n    url: http://localhost:3001/sse\r\n  puppeteer:\r\n    type: stdio\r\n    command: npx\r\n    args:\r\n      - -y\r\n      - \"@modelcontextprotocol/server-puppeteer\"\r\n  filesystem:\r\n    # type: stdio\r\n    command: npx\r\n    args:\r\n      - -y\r\n      - \"@modelcontextprotocol/server-filesystem\"\r\n      - /home/user/LibreChat/\r\n    iconPath: /home/user/LibreChat/client/public/assets/logo.svg\r\n  mcp-obsidian:\r\n    command: npx\r\n    args:\r\n      - -y\r\n      - \"mcp-obsidian\"\r\n      - /path/to/obsidian/vault\r\n\r\n# Definition of custom endpoints\r\nendpoints:\r\n  # assistants:\r\n  #   disableBuilder: false # Disable Assistants Builder Interface by setting to `true`\r\n  #   pollIntervalMs: 3000  # Polling interval for checking assistant updates\r\n  #   timeoutMs: 180000  # Timeout for assistant operations\r\n  #   # Should only be one or the other, either `supportedIds` or `excludedIds`\r\n  #   supportedIds: [\"asst_supportedAssistantId1\", \"asst_supportedAssistantId2\"]\r\n  #   # excludedIds: [\"asst_excludedAssistantId\"]\r\n  #   Only show assistants that the user created or that were created externally (e.g. in Assistants playground).\r\n  #   # privateAssistants: false # Does not work with `supportedIds` or `excludedIds`\r\n  #   # (optional) Models that support retrieval, will default to latest known OpenAI models that support the feature\r\n  #   retrievalModels: [\"gpt-4-turbo-preview\"]\r\n  #   # (optional) Assistant Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.\r\n  #   capabilities: [\"code_interpreter\", \"retrieval\", \"actions\", \"tools\", \"image_vision\"]\r\n  agents:\r\n    (optional) Maximum recursion depth for agents, defaults to 25\r\n    recursionLimit: 50\r\n    (optional) Disable the builder interface for agents\r\n    disableBuilder: true\r\n    (optional) Agent Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.\r\n    capabilities: []\r\n  custom:\r\n    # Groq Example\r\n    - name: 'groq'\r\n      apiKey: '${GROQ_API_KEY}'\r\n      baseURL: 'https://api.groq.com/openai/v1/'\r\n      models:\r\n        default:\r\n          [\r\n            'llama3-70b-8192',\r\n            'llama3-8b-8192',\r\n            'llama2-70b-4096',\r\n            'mixtral-8x7b-32768',\r\n            'gemma-7b-it',\r\n          ]\r\n        fetch: false\r\n      titleConvo: true\r\n      titleModel: 'mixtral-8x7b-32768'\r\n      modelDisplayLabel: 'groq'\r\n\r\n    # Mistral AI Example\r\n    - name: 'Mistral' # Unique name for the endpoint\r\n      # For `apiKey` and `baseURL`, you can use environment variables that you define.\r\n      # recommended environment variables:\r\n      apiKey: '${MISTRAL_API_KEY}'\r\n      baseURL: 'https://api.mistral.ai/v1'\r\n\r\n      # Models configuration\r\n      models:\r\n        # List of default models to use. At least one value is required.\r\n        default: ['mistral-tiny', 'mistral-small', 'mistral-medium']\r\n        # Fetch option: Set to true to fetch models from API.\r\n        fetch: true # Defaults to false.\r\n\r\n      # Optional configurations\r\n\r\n      # Title Conversation setting\r\n      titleConvo: true # Set to true to enable title conversation\r\n\r\n      # Title Method: Choose between \"completion\" or \"functions\".\r\n      # titleMethod: \"completion\"  # Defaults to \"completion\" if omitted.\r\n\r\n      # Title Model: Specify the model to use for titles.\r\n      titleModel: 'mistral-tiny' # Defaults to \"gpt-3.5-turbo\" if omitted.\r\n\r\n      # Summarize setting: Set to true to enable summarization.\r\n      # summarize: false\r\n\r\n      # Summary Model: Specify the model to use if summarization is enabled.\r\n      # summaryModel: \"mistral-tiny\"  # Defaults to \"gpt-3.5-turbo\" if omitted.\r\n\r\n      # Force Prompt setting: If true, sends a `prompt` parameter instead of `messages`.\r\n      # forcePrompt: false\r\n\r\n      # The label displayed for the AI model in messages.\r\n      modelDisplayLabel: 'Mistral' # Default is \"AI\" when not set.\r\n\r\n      # Add additional parameters to the request. Default params will be overwritten.\r\n      # addParams:\r\n      # safe_prompt: true # This field is specific to Mistral AI: https://docs.mistral.ai/api/\r\n\r\n      # Drop Default params parameters from the request. See default params in guide linked below.\r\n      # NOTE: For Mistral, it is necessary to drop the following parameters or you will encounter a 422 Error:\r\n      dropParams: ['stop', 'user', 'frequency_penalty', 'presence_penalty']\r\n\r\n    # OpenRouter Example\r\n    - name: 'OpenRouter'\r\n      # For `apiKey` and `baseURL`, you can use environment variables that you define.\r\n      # recommended environment variables:\r\n      # Known issue: you should not use `OPENROUTER_API_KEY` as it will then override the `openAI` endpoint to use OpenRouter as well.\r\n      apiKey: '${OPENROUTER_KEY}'\r\n      baseURL: 'https://openrouter.ai/api/v1'\r\n      models:\r\n        default: ['meta-llama/llama-3-70b-instruct']\r\n        fetch: true\r\n      titleConvo: true\r\n      titleModel: 'meta-llama/llama-3-70b-instruct'\r\n      # Recommended: Drop the stop parameter from the request as Openrouter models use a variety of stop tokens.\r\n      dropParams: ['stop']\r\n      modelDisplayLabel: 'OpenRouter'\r\n      \r\n    # Portkey AI Example\r\n    - name: \"Portkey\"\r\n      apiKey: \"dummy\"  \r\n      baseURL: 'https://api.portkey.ai/v1'\r\n      headers:\r\n          x-portkey-api-key: [REDACTED]          x-portkey-virtual-key: '${PORTKEY_OPENAI_VIRTUAL_KEY}'\r\n      models:\r\n          default: ['gpt-4o-mini', 'gpt-4o', 'chatgpt-4o-latest']\r\n          fetch: true\r\n      titleConvo: true\r\n      titleModel: 'current_model'\r\n      summarize: false\r\n      summaryModel: 'current_model'\r\n      forcePrompt: false\r\n      modelDisplayLabel: 'Portkey'\r\n      iconURL: https://images.crunchbase.com/image/upload/c_pad,f_auto,q_auto:eco,dpr_1/rjqy7ghvjoiu4cd1xjbf\r\n# fileConfig:\r\n#   endpoints:\r\n#     assistants:\r\n#       fileLimit: 5\r\n#       fileSizeLimit: 10  # Maximum size for an individual file in MB\r\n#       totalSizeLimit: 50  # Maximum total size for all files in a single request in MB\r\n#       supportedMimeTypes:\r\n#         - \"image/.*\"\r\n#         - \"application/pdf\"\r\n#     openAI:\r\n#       disabled: true  # Disables file uploading to the OpenAI endpoint\r\n#     default:\r\n#       totalSizeLimit: 20\r\n#     YourCustomEndpointName:\r\n#       fileLimit: 2\r\n#       fileSizeLimit: 5\r\n#   serverFileSizeLimit: 100  # Global server file size limit in MB\r\n#   avatarSizeLimit: 2  # Limit for user avatar image size in MB\r\n# See the Custom Configuration Guide for more information on Assistants Config:\r\n# https://www.librechat.ai/docs/configuration/librechat_yaml/object_structure/assistants_endpoint\r\n","column":18,"line":152,"name":null,"position":6068,"snippet":" 150 |   #   capabilities: [\"code_interpreter\", \"retriev ...\n 151 |   agents:\n 152 |     (optional) Maximum recursion depth for agents ...\n 153 |     recursionLimit: 50\n-------------------------^\n 154 |     (optional) Disable the builder interface for  ...\n 155 |     disableBuilder: true"},"message":"Config file YAML format is invalid: bad indentation of a mapping entry (153:19)\n\n 150 |   #   capabilities: [\"code_interpreter\", \"retriev ...\n 151 |   agents:\n 152 |     (optional) Maximum recursion depth for agents ...\n 153 |     recursionLimit: 50\n-------------------------^\n 154 |     (optional) Disable the builder interface for  ...\n 155 |     disableBuilder: true","name":"YAMLException","reason":"bad indentation of a mapping entry","stack":"YAMLException: bad indentation of a mapping entry (153:19)\n\n 150 |   #   capabilities: [\"code_interpreter\", \"retriev ...\n 151 |   agents:\n 152 |     (optional) Maximum recursion depth for agents ...\n 153 |     recursionLimit: 50\n-------------------------^\n 154 |     (optional) Disable the builder interface for  ...\n 155 |     disableBuilder: true\n    at generateError (/app/node_modules/js-yaml/lib/loader.js:183:10)\n    at throwError (/app/node_modules/js-yaml/lib/loader.js:187:9)\n    at readBlockMapping (/app/node_modules/js-yaml/lib/loader.js:1182:7)\n    at composeNode (/app/node_modules/js-yaml/lib/loader.js:1441:12)\n    at readBlockMapping (/app/node_modules/js-yaml/lib/loader.js:1164:11)\n    at composeNode (/app/node_modules/js-yaml/lib/loader.js:1441:12)\n    at readDocument (/app/node_modules/js-yaml/lib/loader.js:1625:3)\n    at loadDocuments (/app/node_modules/js-yaml/lib/loader.js:1688:5)\n    at Object.load (/app/node_modules/js-yaml/lib/loader.js:1714:19)\n    at loadYaml (/app/api/utils/loadYaml.js:7:17)"}
{"level":"error","mark":{"buffer":"# For more information, see the Configuration Guide:\r\n# https://www.librechat.ai/docs/configuration/librechat_yaml\r\n\r\n# Configuration version (required)\r\nversion: 1.2.1\r\n\r\n# Cache settings: Set to true to enable caching\r\ncache: true\r\n\r\n# Custom interface configuration\r\ninterface:\r\n  # Privacy policy settings\r\n  privacyPolicy:\r\n    externalUrl: 'https://librechat.ai/privacy-policy'\r\n    openNewTab: true\r\n\r\n  # Terms of service\r\n  termsOfService:\r\n    externalUrl: 'https://librechat.ai/tos'\r\n    openNewTab: true\r\n    modalAcceptance: true\r\n    modalTitle: \"Terms of Service for LibreChat\"\r\n    modalContent: |\r\n      # Terms and Conditions for LibreChat\r\n\r\n      *Effective Date: February 18, 2024*\r\n\r\n      Welcome to LibreChat, the informational website for the open-source AI chat platform, available at https://librechat.ai. These Terms of Service (\"Terms\") govern your use of our website and the services we offer. By accessing or using the Website, you agree to be bound by these Terms and our Privacy Policy, accessible at https://librechat.ai//privacy.\r\n\r\n      ## 1. Ownership\r\n\r\n      Upon purchasing a package from LibreChat, you are granted the right to download and use the code for accessing an admin panel for LibreChat. While you own the downloaded code, you are expressly prohibited from reselling, redistributing, or otherwise transferring the code to third parties without explicit permission from LibreChat.\r\n\r\n      ## 2. User Data\r\n\r\n      We collect personal data, such as your name, email address, and payment information, as described in our Privacy Policy. This information is collected to provide and improve our services, process transactions, and communicate with you.\r\n\r\n      ## 3. Non-Personal Data Collection\r\n\r\n      The Website uses cookies to enhance user experience, analyze site usage, and facilitate certain functionalities. By using the Website, you consent to the use of cookies in accordance with our Privacy Policy.\r\n\r\n      ## 4. Use of the Website\r\n\r\n      You agree to use the Website only for lawful purposes and in a manner that does not infringe the rights of, restrict, or inhibit anyone else's use and enjoyment of the Website. Prohibited behavior includes harassing or causing distress or inconvenience to any person, transmitting obscene or offensive content, or disrupting the normal flow of dialogue within the Website.\r\n\r\n      ## 5. Governing Law\r\n\r\n      These Terms shall be governed by and construed in accordance with the laws of the United States, without giving effect to any principles of conflicts of law.\r\n\r\n      ## 6. Changes to the Terms\r\n\r\n      We reserve the right to modify these Terms at any time. We will notify users of any changes by email. Your continued use of the Website after such changes have been notified will constitute your consent to such changes.\r\n\r\n      ## 7. Contact Information\r\n\r\n      If you have any questions about these Terms, please contact us at contact@librechat.ai.\r\n\r\n      By using the Website, you acknowledge that you have read these Terms of Service and agree to be bound by them.\r\n\r\n  endpointsMenu: true\r\n  modelSelect: true\r\n  parameters: true\r\n  sidePanel: true\r\n  presets: true\r\n  prompts: true\r\n  bookmarks: true\r\n  multiConvo: true\r\n  agents: true\r\n\r\n# Example Registration Object Structure (optional)\r\nregistration:\r\n  socialLogins: ['github', 'google', 'discord', 'openid', 'facebook']\r\n  # allowedDomains:\r\n  # - \"gmail.com\"\r\n\r\n# speech:\r\n#   tts:\r\n#     openai:\r\n#       url: ''\r\n#       apiKey: '${TTS_API_KEY}'\r\n#       model: ''\r\n#       voices: ['']\r\n\r\n#  \r\n#   stt:\r\n#     openai:\r\n#       url: ''\r\n#       apiKey: '${STT_API_KEY}'\r\n#       model: ''\r\n\r\n# rateLimits:\r\n#   fileUploads:\r\n#     ipMax: 100\r\n#     ipWindowInMinutes: 60  # Rate limit window for file uploads per IP\r\n#     userMax: 50\r\n#     userWindowInMinutes: 60  # Rate limit window for file uploads per user\r\n#   conversationsImport:\r\n#     ipMax: 100\r\n#     ipWindowInMinutes: 60  # Rate limit window for conversation imports per IP\r\n#     userMax: 50\r\n#     userWindowInMinutes: 60  # Rate limit window for conversation imports per user\r\n\r\n# Example Actions Object Structure\r\nactions:\r\n  allowedDomains:\r\n    - \"swapi.dev\"\r\n    - \"librechat.ai\"\r\n    - \"google.com\"\r\n\r\n# Example MCP Servers Object Structure\r\nmcpServers:\r\n  everything:\r\n    # type: sse # type can optionally be omitted\r\n    url: http://localhost:3001/sse\r\n  puppeteer:\r\n    type: stdio\r\n    command: npx\r\n    args:\r\n      - -y\r\n      - \"@modelcontextprotocol/server-puppeteer\"\r\n  filesystem:\r\n    # type: stdio\r\n    command: npx\r\n    args:\r\n      - -y\r\n      - \"@modelcontextprotocol/server-filesystem\"\r\n      - /home/user/LibreChat/\r\n    iconPath: /home/user/LibreChat/client/public/assets/logo.svg\r\n  mcp-obsidian:\r\n    command: npx\r\n    args:\r\n      - -y\r\n      - \"mcp-obsidian\"\r\n      - /path/to/obsidian/vault\r\n\r\n# Definition of custom endpoints\r\nendpoints:\r\n  # assistants:\r\n  #   disableBuilder: false # Disable Assistants Builder Interface by setting to `true`\r\n  #   pollIntervalMs: 3000  # Polling interval for checking assistant updates\r\n  #   timeoutMs: 180000  # Timeout for assistant operations\r\n  #   # Should only be one or the other, either `supportedIds` or `excludedIds`\r\n  #   supportedIds: [\"asst_supportedAssistantId1\", \"asst_supportedAssistantId2\"]\r\n  #   # excludedIds: [\"asst_excludedAssistantId\"]\r\n  #   Only show assistants that the user created or that were created externally (e.g. in Assistants playground).\r\n  #   # privateAssistants: false # Does not work with `supportedIds` or `excludedIds`\r\n  #   # (optional) Models that support retrieval, will default to latest known OpenAI models that support the feature\r\n  #   retrievalModels: [\"gpt-4-turbo-preview\"]\r\n  #   # (optional) Assistant Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.\r\n  #   capabilities: [\"code_interpreter\", \"retrieval\", \"actions\", \"tools\", \"image_vision\"]\r\n  agents:\r\n    (optional) Maximum recursion depth for agents, defaults to 25\r\n    recursionLimit: 50\r\n    (optional) Disable the builder interface for agents\r\n    disableBuilder: true\r\n    (optional) Agent Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.\r\n    capabilities: []\r\n  custom:\r\n    # Groq Example\r\n    - name: 'groq'\r\n      apiKey: '${GROQ_API_KEY}'\r\n      baseURL: 'https://api.groq.com/openai/v1/'\r\n      models:\r\n        default:\r\n          [\r\n            'llama3-70b-8192',\r\n            'llama3-8b-8192',\r\n            'llama2-70b-4096',\r\n            'mixtral-8x7b-32768',\r\n            'gemma-7b-it',\r\n          ]\r\n        fetch: false\r\n      titleConvo: true\r\n      titleModel: 'mixtral-8x7b-32768'\r\n      modelDisplayLabel: 'groq'\r\n\r\n    # Mistral AI Example\r\n    - name: 'Mistral' # Unique name for the endpoint\r\n      # For `apiKey` and `baseURL`, you can use environment variables that you define.\r\n      # recommended environment variables:\r\n      apiKey: '${MISTRAL_API_KEY}'\r\n      baseURL: 'https://api.mistral.ai/v1'\r\n\r\n      # Models configuration\r\n      models:\r\n        # List of default models to use. At least one value is required.\r\n        default: ['mistral-tiny', 'mistral-small', 'mistral-medium']\r\n        # Fetch option: Set to true to fetch models from API.\r\n        fetch: true # Defaults to false.\r\n\r\n      # Optional configurations\r\n\r\n      # Title Conversation setting\r\n      titleConvo: true # Set to true to enable title conversation\r\n\r\n      # Title Method: Choose between \"completion\" or \"functions\".\r\n      # titleMethod: \"completion\"  # Defaults to \"completion\" if omitted.\r\n\r\n      # Title Model: Specify the model to use for titles.\r\n      titleModel: 'mistral-tiny' # Defaults to \"gpt-3.5-turbo\" if omitted.\r\n\r\n      # Summarize setting: Set to true to enable summarization.\r\n      # summarize: false\r\n\r\n      # Summary Model: Specify the model to use if summarization is enabled.\r\n      # summaryModel: \"mistral-tiny\"  # Defaults to \"gpt-3.5-turbo\" if omitted.\r\n\r\n      # Force Prompt setting: If true, sends a `prompt` parameter instead of `messages`.\r\n      # forcePrompt: false\r\n\r\n      # The label displayed for the AI model in messages.\r\n      modelDisplayLabel: 'Mistral' # Default is \"AI\" when not set.\r\n\r\n      # Add additional parameters to the request. Default params will be overwritten.\r\n      # addParams:\r\n      # safe_prompt: true # This field is specific to Mistral AI: https://docs.mistral.ai/api/\r\n\r\n      # Drop Default params parameters from the request. See default params in guide linked below.\r\n      # NOTE: For Mistral, it is necessary to drop the following parameters or you will encounter a 422 Error:\r\n      dropParams: ['stop', 'user', 'frequency_penalty', 'presence_penalty']\r\n\r\n    # OpenRouter Example\r\n    - name: 'OpenRouter'\r\n      # For `apiKey` and `baseURL`, you can use environment variables that you define.\r\n      # recommended environment variables:\r\n      # Known issue: you should not use `OPENROUTER_API_KEY` as it will then override the `openAI` endpoint to use OpenRouter as well.\r\n      apiKey: '${OPENROUTER_KEY}'\r\n      baseURL: 'https://openrouter.ai/api/v1'\r\n      models:\r\n        default: ['meta-llama/llama-3-70b-instruct']\r\n        fetch: true\r\n      titleConvo: true\r\n      titleModel: 'meta-llama/llama-3-70b-instruct'\r\n      # Recommended: Drop the stop parameter from the request as Openrouter models use a variety of stop tokens.\r\n      dropParams: ['stop']\r\n      modelDisplayLabel: 'OpenRouter'\r\n      \r\n    # Portkey AI Example\r\n    - name: \"Portkey\"\r\n      apiKey: \"dummy\"  \r\n      baseURL: 'https://api.portkey.ai/v1'\r\n      headers:\r\n          x-portkey-api-key: [REDACTED]          x-portkey-virtual-key: '${PORTKEY_OPENAI_VIRTUAL_KEY}'\r\n      models:\r\n          default: ['gpt-4o-mini', 'gpt-4o', 'chatgpt-4o-latest']\r\n          fetch: true\r\n      titleConvo: true\r\n      titleModel: 'current_model'\r\n      summarize: false\r\n      summaryModel: 'current_model'\r\n      forcePrompt: false\r\n      modelDisplayLabel: 'Portkey'\r\n      iconURL: https://images.crunchbase.com/image/upload/c_pad,f_auto,q_auto:eco,dpr_1/rjqy7ghvjoiu4cd1xjbf\r\n# fileConfig:\r\n#   endpoints:\r\n#     assistants:\r\n#       fileLimit: 5\r\n#       fileSizeLimit: 10  # Maximum size for an individual file in MB\r\n#       totalSizeLimit: 50  # Maximum total size for all files in a single request in MB\r\n#       supportedMimeTypes:\r\n#         - \"image/.*\"\r\n#         - \"application/pdf\"\r\n#     openAI:\r\n#       disabled: true  # Disables file uploading to the OpenAI endpoint\r\n#     default:\r\n#       totalSizeLimit: 20\r\n#     YourCustomEndpointName:\r\n#       fileLimit: 2\r\n#       fileSizeLimit: 5\r\n#   serverFileSizeLimit: 100  # Global server file size limit in MB\r\n#   avatarSizeLimit: 2  # Limit for user avatar image size in MB\r\n# See the Custom Configuration Guide for more information on Assistants Config:\r\n# https://www.librechat.ai/docs/configuration/librechat_yaml/object_structure/assistants_endpoint\r\n","column":18,"line":152,"name":null,"position":6068,"snippet":" 150 |   #   capabilities: [\"code_interpreter\", \"retriev ...\n 151 |   agents:\n 152 |     (optional) Maximum recursion depth for agents ...\n 153 |     recursionLimit: 50\n-------------------------^\n 154 |     (optional) Disable the builder interface for  ...\n 155 |     disableBuilder: true"},"message":"Config file YAML format is invalid: bad indentation of a mapping entry (153:19)\n\n 150 |   #   capabilities: [\"code_interpreter\", \"retriev ...\n 151 |   agents:\n 152 |     (optional) Maximum recursion depth for agents ...\n 153 |     recursionLimit: 50\n-------------------------^\n 154 |     (optional) Disable the builder interface for  ...\n 155 |     disableBuilder: true","name":"YAMLException","reason":"bad indentation of a mapping entry","stack":"YAMLException: bad indentation of a mapping entry (153:19)\n\n 150 |   #   capabilities: [\"code_interpreter\", \"retriev ...\n 151 |   agents:\n 152 |     (optional) Maximum recursion depth for agents ...\n 153 |     recursionLimit: 50\n-------------------------^\n 154 |     (optional) Disable the builder interface for  ...\n 155 |     disableBuilder: true\n    at generateError (/app/node_modules/js-yaml/lib/loader.js:183:10)\n    at throwError (/app/node_modules/js-yaml/lib/loader.js:187:9)\n    at readBlockMapping (/app/node_modules/js-yaml/lib/loader.js:1182:7)\n    at composeNode (/app/node_modules/js-yaml/lib/loader.js:1441:12)\n    at readBlockMapping (/app/node_modules/js-yaml/lib/loader.js:1164:11)\n    at composeNode (/app/node_modules/js-yaml/lib/loader.js:1441:12)\n    at readDocument (/app/node_modules/js-yaml/lib/loader.js:1625:3)\n    at loadDocuments (/app/node_modules/js-yaml/lib/loader.js:1688:5)\n    at Object.load (/app/node_modules/js-yaml/lib/loader.js:1714:19)\n    at loadYaml (/app/api/utils/loadYaml.js:7:17)"}
{"level":"error","mark":{"buffer":"# For more information, see the Configuration Guide:\r\n# https://www.librechat.ai/docs/configuration/librechat_yaml\r\n\r\n# Configuration version (required)\r\nversion: 1.2.1\r\n\r\n# Cache settings: Set to true to enable caching\r\ncache: true\r\n\r\n# Custom interface configuration\r\ninterface:\r\n  # Privacy policy settings\r\n  privacyPolicy:\r\n    externalUrl: 'https://librechat.ai/privacy-policy'\r\n    openNewTab: true\r\n\r\n  # Terms of service\r\n  termsOfService:\r\n    externalUrl: 'https://librechat.ai/tos'\r\n    openNewTab: true\r\n    modalAcceptance: true\r\n    modalTitle: \"Terms of Service for LibreChat\"\r\n    modalContent: |\r\n      # Terms and Conditions for LibreChat\r\n\r\n      *Effective Date: February 18, 2024*\r\n\r\n      Welcome to LibreChat, the informational website for the open-source AI chat platform, available at https://librechat.ai. These Terms of Service (\"Terms\") govern your use of our website and the services we offer. By accessing or using the Website, you agree to be bound by these Terms and our Privacy Policy, accessible at https://librechat.ai//privacy.\r\n\r\n      ## 1. Ownership\r\n\r\n      Upon purchasing a package from LibreChat, you are granted the right to download and use the code for accessing an admin panel for LibreChat. While you own the downloaded code, you are expressly prohibited from reselling, redistributing, or otherwise transferring the code to third parties without explicit permission from LibreChat.\r\n\r\n      ## 2. User Data\r\n\r\n      We collect personal data, such as your name, email address, and payment information, as described in our Privacy Policy. This information is collected to provide and improve our services, process transactions, and communicate with you.\r\n\r\n      ## 3. Non-Personal Data Collection\r\n\r\n      The Website uses cookies to enhance user experience, analyze site usage, and facilitate certain functionalities. By using the Website, you consent to the use of cookies in accordance with our Privacy Policy.\r\n\r\n      ## 4. Use of the Website\r\n\r\n      You agree to use the Website only for lawful purposes and in a manner that does not infringe the rights of, restrict, or inhibit anyone else's use and enjoyment of the Website. Prohibited behavior includes harassing or causing distress or inconvenience to any person, transmitting obscene or offensive content, or disrupting the normal flow of dialogue within the Website.\r\n\r\n      ## 5. Governing Law\r\n\r\n      These Terms shall be governed by and construed in accordance with the laws of the United States, without giving effect to any principles of conflicts of law.\r\n\r\n      ## 6. Changes to the Terms\r\n\r\n      We reserve the right to modify these Terms at any time. We will notify users of any changes by email. Your continued use of the Website after such changes have been notified will constitute your consent to such changes.\r\n\r\n      ## 7. Contact Information\r\n\r\n      If you have any questions about these Terms, please contact us at contact@librechat.ai.\r\n\r\n      By using the Website, you acknowledge that you have read these Terms of Service and agree to be bound by them.\r\n\r\n  endpointsMenu: true\r\n  modelSelect: true\r\n  parameters: true\r\n  sidePanel: true\r\n  presets: true\r\n  prompts: true\r\n  bookmarks: true\r\n  multiConvo: true\r\n  agents: true\r\n\r\n# Example Registration Object Structure (optional)\r\nregistration:\r\n  socialLogins: ['github', 'google', 'discord', 'openid', 'facebook']\r\n  # allowedDomains:\r\n  # - \"gmail.com\"\r\n\r\n# speech:\r\n#   tts:\r\n#     openai:\r\n#       url: ''\r\n#       apiKey: '${TTS_API_KEY}'\r\n#       model: ''\r\n#       voices: ['']\r\n\r\n#  \r\n#   stt:\r\n#     openai:\r\n#       url: ''\r\n#       apiKey: '${STT_API_KEY}'\r\n#       model: ''\r\n\r\n# rateLimits:\r\n#   fileUploads:\r\n#     ipMax: 100\r\n#     ipWindowInMinutes: 60  # Rate limit window for file uploads per IP\r\n#     userMax: 50\r\n#     userWindowInMinutes: 60  # Rate limit window for file uploads per user\r\n#   conversationsImport:\r\n#     ipMax: 100\r\n#     ipWindowInMinutes: 60  # Rate limit window for conversation imports per IP\r\n#     userMax: 50\r\n#     userWindowInMinutes: 60  # Rate limit window for conversation imports per user\r\n\r\n# Example Actions Object Structure\r\nactions:\r\n  allowedDomains:\r\n    - \"swapi.dev\"\r\n    - \"librechat.ai\"\r\n    - \"google.com\"\r\n\r\n# Example MCP Servers Object Structure\r\nmcpServers:\r\n  everything:\r\n    # type: sse # type can optionally be omitted\r\n    url: http://localhost:3001/sse\r\n  puppeteer:\r\n    type: stdio\r\n    command: npx\r\n    args:\r\n      - -y\r\n      - \"@modelcontextprotocol/server-puppeteer\"\r\n  filesystem:\r\n    # type: stdio\r\n    command: npx\r\n    args:\r\n      - -y\r\n      - \"@modelcontextprotocol/server-filesystem\"\r\n      - /home/user/LibreChat/\r\n    iconPath: /home/user/LibreChat/client/public/assets/logo.svg\r\n  mcp-obsidian:\r\n    command: npx\r\n    args:\r\n      - -y\r\n      - \"mcp-obsidian\"\r\n      - /path/to/obsidian/vault\r\n\r\n# Definition of custom endpoints\r\nendpoints:\r\n  # assistants:\r\n  #   disableBuilder: false # Disable Assistants Builder Interface by setting to `true`\r\n  #   pollIntervalMs: 3000  # Polling interval for checking assistant updates\r\n  #   timeoutMs: 180000  # Timeout for assistant operations\r\n  #   # Should only be one or the other, either `supportedIds` or `excludedIds`\r\n  #   supportedIds: [\"asst_supportedAssistantId1\", \"asst_supportedAssistantId2\"]\r\n  #   # excludedIds: [\"asst_excludedAssistantId\"]\r\n  #   Only show assistants that the user created or that were created externally (e.g. in Assistants playground).\r\n  #   # privateAssistants: false # Does not work with `supportedIds` or `excludedIds`\r\n  #   # (optional) Models that support retrieval, will default to latest known OpenAI models that support the feature\r\n  #   retrievalModels: [\"gpt-4-turbo-preview\"]\r\n  #   # (optional) Assistant Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.\r\n  #   capabilities: [\"code_interpreter\", \"retrieval\", \"actions\", \"tools\", \"image_vision\"]\r\n  agents:\r\n    (optional) Maximum recursion depth for agents, defaults to 25\r\n    recursionLimit: 50\r\n    (optional) Disable the builder interface for agents\r\n    disableBuilder: true\r\n    (optional) Agent Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.\r\n    capabilities: []\r\n  custom:\r\n    # Groq Example\r\n    - name: 'groq'\r\n      apiKey: '${GROQ_API_KEY}'\r\n      baseURL: 'https://api.groq.com/openai/v1/'\r\n      models:\r\n        default:\r\n          [\r\n            'llama3-70b-8192',\r\n            'llama3-8b-8192',\r\n            'llama2-70b-4096',\r\n            'mixtral-8x7b-32768',\r\n            'gemma-7b-it',\r\n          ]\r\n        fetch: false\r\n      titleConvo: true\r\n      titleModel: 'mixtral-8x7b-32768'\r\n      modelDisplayLabel: 'groq'\r\n\r\n    # Mistral AI Example\r\n    - name: 'Mistral' # Unique name for the endpoint\r\n      # For `apiKey` and `baseURL`, you can use environment variables that you define.\r\n      # recommended environment variables:\r\n      apiKey: '${MISTRAL_API_KEY}'\r\n      baseURL: 'https://api.mistral.ai/v1'\r\n\r\n      # Models configuration\r\n      models:\r\n        # List of default models to use. At least one value is required.\r\n        default: ['mistral-tiny', 'mistral-small', 'mistral-medium']\r\n        # Fetch option: Set to true to fetch models from API.\r\n        fetch: true # Defaults to false.\r\n\r\n      # Optional configurations\r\n\r\n      # Title Conversation setting\r\n      titleConvo: true # Set to true to enable title conversation\r\n\r\n      # Title Method: Choose between \"completion\" or \"functions\".\r\n      # titleMethod: \"completion\"  # Defaults to \"completion\" if omitted.\r\n\r\n      # Title Model: Specify the model to use for titles.\r\n      titleModel: 'mistral-tiny' # Defaults to \"gpt-3.5-turbo\" if omitted.\r\n\r\n      # Summarize setting: Set to true to enable summarization.\r\n      # summarize: false\r\n\r\n      # Summary Model: Specify the model to use if summarization is enabled.\r\n      # summaryModel: \"mistral-tiny\"  # Defaults to \"gpt-3.5-turbo\" if omitted.\r\n\r\n      # Force Prompt setting: If true, sends a `prompt` parameter instead of `messages`.\r\n      # forcePrompt: false\r\n\r\n      # The label displayed for the AI model in messages.\r\n      modelDisplayLabel: 'Mistral' # Default is \"AI\" when not set.\r\n\r\n      # Add additional parameters to the request. Default params will be overwritten.\r\n      # addParams:\r\n      # safe_prompt: true # This field is specific to Mistral AI: https://docs.mistral.ai/api/\r\n\r\n      # Drop Default params parameters from the request. See default params in guide linked below.\r\n      # NOTE: For Mistral, it is necessary to drop the following parameters or you will encounter a 422 Error:\r\n      dropParams: ['stop', 'user', 'frequency_penalty', 'presence_penalty']\r\n\r\n    # OpenRouter Example\r\n    - name: 'OpenRouter'\r\n      # For `apiKey` and `baseURL`, you can use environment variables that you define.\r\n      # recommended environment variables:\r\n      # Known issue: you should not use `OPENROUTER_API_KEY` as it will then override the `openAI` endpoint to use OpenRouter as well.\r\n      apiKey: '${OPENROUTER_KEY}'\r\n      baseURL: 'https://openrouter.ai/api/v1'\r\n      models:\r\n        default: ['meta-llama/llama-3-70b-instruct']\r\n        fetch: true\r\n      titleConvo: true\r\n      titleModel: 'meta-llama/llama-3-70b-instruct'\r\n      # Recommended: Drop the stop parameter from the request as Openrouter models use a variety of stop tokens.\r\n      dropParams: ['stop']\r\n      modelDisplayLabel: 'OpenRouter'\r\n      \r\n    # Portkey AI Example\r\n    - name: \"Portkey\"\r\n      apiKey: \"dummy\"  \r\n      baseURL: 'https://api.portkey.ai/v1'\r\n      headers:\r\n          x-portkey-api-key: [REDACTED]          x-portkey-virtual-key: '${PORTKEY_OPENAI_VIRTUAL_KEY}'\r\n      models:\r\n          default: ['gpt-4o-mini', 'gpt-4o', 'chatgpt-4o-latest']\r\n          fetch: true\r\n      titleConvo: true\r\n      titleModel: 'current_model'\r\n      summarize: false\r\n      summaryModel: 'current_model'\r\n      forcePrompt: false\r\n      modelDisplayLabel: 'Portkey'\r\n      iconURL: https://images.crunchbase.com/image/upload/c_pad,f_auto,q_auto:eco,dpr_1/rjqy7ghvjoiu4cd1xjbf\r\n# fileConfig:\r\n#   endpoints:\r\n#     assistants:\r\n#       fileLimit: 5\r\n#       fileSizeLimit: 10  # Maximum size for an individual file in MB\r\n#       totalSizeLimit: 50  # Maximum total size for all files in a single request in MB\r\n#       supportedMimeTypes:\r\n#         - \"image/.*\"\r\n#         - \"application/pdf\"\r\n#     openAI:\r\n#       disabled: true  # Disables file uploading to the OpenAI endpoint\r\n#     default:\r\n#       totalSizeLimit: 20\r\n#     YourCustomEndpointName:\r\n#       fileLimit: 2\r\n#       fileSizeLimit: 5\r\n#   serverFileSizeLimit: 100  # Global server file size limit in MB\r\n#   avatarSizeLimit: 2  # Limit for user avatar image size in MB\r\n# See the Custom Configuration Guide for more information on Assistants Config:\r\n# https://www.librechat.ai/docs/configuration/librechat_yaml/object_structure/assistants_endpoint\r\n","column":18,"line":152,"name":null,"position":6068,"snippet":" 150 |   #   capabilities: [\"code_interpreter\", \"retriev ...\n 151 |   agents:\n 152 |     (optional) Maximum recursion depth for agents ...\n 153 |     recursionLimit: 50\n-------------------------^\n 154 |     (optional) Disable the builder interface for  ...\n 155 |     disableBuilder: true"},"message":"Config file YAML format is invalid: bad indentation of a mapping entry (153:19)\n\n 150 |   #   capabilities: [\"code_interpreter\", \"retriev ...\n 151 |   agents:\n 152 |     (optional) Maximum recursion depth for agents ...\n 153 |     recursionLimit: 50\n-------------------------^\n 154 |     (optional) Disable the builder interface for  ...\n 155 |     disableBuilder: true","name":"YAMLException","reason":"bad indentation of a mapping entry","stack":"YAMLException: bad indentation of a mapping entry (153:19)\n\n 150 |   #   capabilities: [\"code_interpreter\", \"retriev ...\n 151 |   agents:\n 152 |     (optional) Maximum recursion depth for agents ...\n 153 |     recursionLimit: 50\n-------------------------^\n 154 |     (optional) Disable the builder interface for  ...\n 155 |     disableBuilder: true\n    at generateError (/app/node_modules/js-yaml/lib/loader.js:183:10)\n    at throwError (/app/node_modules/js-yaml/lib/loader.js:187:9)\n    at readBlockMapping (/app/node_modules/js-yaml/lib/loader.js:1182:7)\n    at composeNode (/app/node_modules/js-yaml/lib/loader.js:1441:12)\n    at readBlockMapping (/app/node_modules/js-yaml/lib/loader.js:1164:11)\n    at composeNode (/app/node_modules/js-yaml/lib/loader.js:1441:12)\n    at readDocument (/app/node_modules/js-yaml/lib/loader.js:1625:3)\n    at loadDocuments (/app/node_modules/js-yaml/lib/loader.js:1688:5)\n    at Object.load (/app/node_modules/js-yaml/lib/loader.js:1714:19)\n    at loadYaml (/app/api/utils/loadYaml.js:7:17)"}
{"level":"error","mark":{"buffer":"# For more information, see the Configuration Guide:\r\n# https://www.librechat.ai/docs/configuration/librechat_yaml\r\n\r\n# Configuration version (required)\r\nversion: 1.2.1\r\n\r\n# Cache settings: Set to true to enable caching\r\ncache: true\r\n\r\n# Custom interface configuration\r\ninterface:\r\n  # Privacy policy settings\r\n  privacyPolicy:\r\n    externalUrl: 'https://librechat.ai/privacy-policy'\r\n    openNewTab: true\r\n\r\n  # Terms of service\r\n  termsOfService:\r\n    externalUrl: 'https://librechat.ai/tos'\r\n    openNewTab: true\r\n    modalAcceptance: true\r\n    modalTitle: \"Terms of Service for LibreChat\"\r\n    modalContent: |\r\n      # Terms and Conditions for LibreChat\r\n\r\n      *Effective Date: February 18, 2024*\r\n\r\n      Welcome to LibreChat, the informational website for the open-source AI chat platform, available at https://librechat.ai. These Terms of Service (\"Terms\") govern your use of our website and the services we offer. By accessing or using the Website, you agree to be bound by these Terms and our Privacy Policy, accessible at https://librechat.ai//privacy.\r\n\r\n      ## 1. Ownership\r\n\r\n      Upon purchasing a package from LibreChat, you are granted the right to download and use the code for accessing an admin panel for LibreChat. While you own the downloaded code, you are expressly prohibited from reselling, redistributing, or otherwise transferring the code to third parties without explicit permission from LibreChat.\r\n\r\n      ## 2. User Data\r\n\r\n      We collect personal data, such as your name, email address, and payment information, as described in our Privacy Policy. This information is collected to provide and improve our services, process transactions, and communicate with you.\r\n\r\n      ## 3. Non-Personal Data Collection\r\n\r\n      The Website uses cookies to enhance user experience, analyze site usage, and facilitate certain functionalities. By using the Website, you consent to the use of cookies in accordance with our Privacy Policy.\r\n\r\n      ## 4. Use of the Website\r\n\r\n      You agree to use the Website only for lawful purposes and in a manner that does not infringe the rights of, restrict, or inhibit anyone else's use and enjoyment of the Website. Prohibited behavior includes harassing or causing distress or inconvenience to any person, transmitting obscene or offensive content, or disrupting the normal flow of dialogue within the Website.\r\n\r\n      ## 5. Governing Law\r\n\r\n      These Terms shall be governed by and construed in accordance with the laws of the United States, without giving effect to any principles of conflicts of law.\r\n\r\n      ## 6. Changes to the Terms\r\n\r\n      We reserve the right to modify these Terms at any time. We will notify users of any changes by email. Your continued use of the Website after such changes have been notified will constitute your consent to such changes.\r\n\r\n      ## 7. Contact Information\r\n\r\n      If you have any questions about these Terms, please contact us at contact@librechat.ai.\r\n\r\n      By using the Website, you acknowledge that you have read these Terms of Service and agree to be bound by them.\r\n\r\n  endpointsMenu: true\r\n  modelSelect: true\r\n  parameters: true\r\n  sidePanel: true\r\n  presets: true\r\n  prompts: true\r\n  bookmarks: true\r\n  multiConvo: true\r\n  agents: true\r\n\r\n# Example Registration Object Structure (optional)\r\nregistration:\r\n  socialLogins: ['github', 'google', 'discord', 'openid', 'facebook']\r\n  # allowedDomains:\r\n  # - \"gmail.com\"\r\n\r\n# speech:\r\n#   tts:\r\n#     openai:\r\n#       url: ''\r\n#       apiKey: '${TTS_API_KEY}'\r\n#       model: ''\r\n#       voices: ['']\r\n\r\n#  \r\n#   stt:\r\n#     openai:\r\n#       url: ''\r\n#       apiKey: '${STT_API_KEY}'\r\n#       model: ''\r\n\r\n# rateLimits:\r\n#   fileUploads:\r\n#     ipMax: 100\r\n#     ipWindowInMinutes: 60  # Rate limit window for file uploads per IP\r\n#     userMax: 50\r\n#     userWindowInMinutes: 60  # Rate limit window for file uploads per user\r\n#   conversationsImport:\r\n#     ipMax: 100\r\n#     ipWindowInMinutes: 60  # Rate limit window for conversation imports per IP\r\n#     userMax: 50\r\n#     userWindowInMinutes: 60  # Rate limit window for conversation imports per user\r\n\r\n# Example Actions Object Structure\r\nactions:\r\n  allowedDomains:\r\n    - \"swapi.dev\"\r\n    - \"librechat.ai\"\r\n    - \"google.com\"\r\n\r\n# Example MCP Servers Object Structure\r\nmcpServers:\r\n  everything:\r\n    # type: sse # type can optionally be omitted\r\n    url: http://localhost:3001/sse\r\n  puppeteer:\r\n    type: stdio\r\n    command: npx\r\n    args:\r\n      - -y\r\n      - \"@modelcontextprotocol/server-puppeteer\"\r\n  filesystem:\r\n    # type: stdio\r\n    command: npx\r\n    args:\r\n      - -y\r\n      - \"@modelcontextprotocol/server-filesystem\"\r\n      - /home/user/LibreChat/\r\n    iconPath: /home/user/LibreChat/client/public/assets/logo.svg\r\n  mcp-obsidian:\r\n    command: npx\r\n    args:\r\n      - -y\r\n      - \"mcp-obsidian\"\r\n      - /path/to/obsidian/vault\r\n\r\n# Definition of custom endpoints\r\nendpoints:\r\n  # assistants:\r\n  #   disableBuilder: false # Disable Assistants Builder Interface by setting to `true`\r\n  #   pollIntervalMs: 3000  # Polling interval for checking assistant updates\r\n  #   timeoutMs: 180000  # Timeout for assistant operations\r\n  #   # Should only be one or the other, either `supportedIds` or `excludedIds`\r\n  #   supportedIds: [\"asst_supportedAssistantId1\", \"asst_supportedAssistantId2\"]\r\n  #   # excludedIds: [\"asst_excludedAssistantId\"]\r\n  #   Only show assistants that the user created or that were created externally (e.g. in Assistants playground).\r\n  #   # privateAssistants: false # Does not work with `supportedIds` or `excludedIds`\r\n  #   # (optional) Models that support retrieval, will default to latest known OpenAI models that support the feature\r\n  #   retrievalModels: [\"gpt-4-turbo-preview\"]\r\n  #   # (optional) Assistant Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.\r\n  #   capabilities: [\"code_interpreter\", \"retrieval\", \"actions\", \"tools\", \"image_vision\"]\r\n  agents:\r\n    (optional) Maximum recursion depth for agents, defaults to 25\r\n    recursionLimit: 50\r\n    (optional) Disable the builder interface for agents\r\n    disableBuilder: true\r\n    (optional) Agent Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.\r\n    capabilities: []\r\n  custom:\r\n    # Groq Example\r\n    - name: 'groq'\r\n      apiKey: '${GROQ_API_KEY}'\r\n      baseURL: 'https://api.groq.com/openai/v1/'\r\n      models:\r\n        default:\r\n          [\r\n            'llama3-70b-8192',\r\n            'llama3-8b-8192',\r\n            'llama2-70b-4096',\r\n            'mixtral-8x7b-32768',\r\n            'gemma-7b-it',\r\n          ]\r\n        fetch: false\r\n      titleConvo: true\r\n      titleModel: 'mixtral-8x7b-32768'\r\n      modelDisplayLabel: 'groq'\r\n\r\n    # Mistral AI Example\r\n    - name: 'Mistral' # Unique name for the endpoint\r\n      # For `apiKey` and `baseURL`, you can use environment variables that you define.\r\n      # recommended environment variables:\r\n      apiKey: '${MISTRAL_API_KEY}'\r\n      baseURL: 'https://api.mistral.ai/v1'\r\n\r\n      # Models configuration\r\n      models:\r\n        # List of default models to use. At least one value is required.\r\n        default: ['mistral-tiny', 'mistral-small', 'mistral-medium']\r\n        # Fetch option: Set to true to fetch models from API.\r\n        fetch: true # Defaults to false.\r\n\r\n      # Optional configurations\r\n\r\n      # Title Conversation setting\r\n      titleConvo: true # Set to true to enable title conversation\r\n\r\n      # Title Method: Choose between \"completion\" or \"functions\".\r\n      # titleMethod: \"completion\"  # Defaults to \"completion\" if omitted.\r\n\r\n      # Title Model: Specify the model to use for titles.\r\n      titleModel: 'mistral-tiny' # Defaults to \"gpt-3.5-turbo\" if omitted.\r\n\r\n      # Summarize setting: Set to true to enable summarization.\r\n      # summarize: false\r\n\r\n      # Summary Model: Specify the model to use if summarization is enabled.\r\n      # summaryModel: \"mistral-tiny\"  # Defaults to \"gpt-3.5-turbo\" if omitted.\r\n\r\n      # Force Prompt setting: If true, sends a `prompt` parameter instead of `messages`.\r\n      # forcePrompt: false\r\n\r\n      # The label displayed for the AI model in messages.\r\n      modelDisplayLabel: 'Mistral' # Default is \"AI\" when not set.\r\n\r\n      # Add additional parameters to the request. Default params will be overwritten.\r\n      # addParams:\r\n      # safe_prompt: true # This field is specific to Mistral AI: https://docs.mistral.ai/api/\r\n\r\n      # Drop Default params parameters from the request. See default params in guide linked below.\r\n      # NOTE: For Mistral, it is necessary to drop the following parameters or you will encounter a 422 Error:\r\n      dropParams: ['stop', 'user', 'frequency_penalty', 'presence_penalty']\r\n\r\n    # OpenRouter Example\r\n    - name: 'OpenRouter'\r\n      # For `apiKey` and `baseURL`, you can use environment variables that you define.\r\n      # recommended environment variables:\r\n      # Known issue: you should not use `OPENROUTER_API_KEY` as it will then override the `openAI` endpoint to use OpenRouter as well.\r\n      apiKey: '${OPENROUTER_KEY}'\r\n      baseURL: 'https://openrouter.ai/api/v1'\r\n      models:\r\n        default: ['meta-llama/llama-3-70b-instruct']\r\n        fetch: true\r\n      titleConvo: true\r\n      titleModel: 'meta-llama/llama-3-70b-instruct'\r\n      # Recommended: Drop the stop parameter from the request as Openrouter models use a variety of stop tokens.\r\n      dropParams: ['stop']\r\n      modelDisplayLabel: 'OpenRouter'\r\n      \r\n    # Portkey AI Example\r\n    - name: \"Portkey\"\r\n      apiKey: \"dummy\"  \r\n      baseURL: 'https://api.portkey.ai/v1'\r\n      headers:\r\n          x-portkey-api-key: [REDACTED]          x-portkey-virtual-key: '${PORTKEY_OPENAI_VIRTUAL_KEY}'\r\n      models:\r\n          default: ['gpt-4o-mini', 'gpt-4o', 'chatgpt-4o-latest']\r\n          fetch: true\r\n      titleConvo: true\r\n      titleModel: 'current_model'\r\n      summarize: false\r\n      summaryModel: 'current_model'\r\n      forcePrompt: false\r\n      modelDisplayLabel: 'Portkey'\r\n      iconURL: https://images.crunchbase.com/image/upload/c_pad,f_auto,q_auto:eco,dpr_1/rjqy7ghvjoiu4cd1xjbf\r\n# fileConfig:\r\n#   endpoints:\r\n#     assistants:\r\n#       fileLimit: 5\r\n#       fileSizeLimit: 10  # Maximum size for an individual file in MB\r\n#       totalSizeLimit: 50  # Maximum total size for all files in a single request in MB\r\n#       supportedMimeTypes:\r\n#         - \"image/.*\"\r\n#         - \"application/pdf\"\r\n#     openAI:\r\n#       disabled: true  # Disables file uploading to the OpenAI endpoint\r\n#     default:\r\n#       totalSizeLimit: 20\r\n#     YourCustomEndpointName:\r\n#       fileLimit: 2\r\n#       fileSizeLimit: 5\r\n#   serverFileSizeLimit: 100  # Global server file size limit in MB\r\n#   avatarSizeLimit: 2  # Limit for user avatar image size in MB\r\n# See the Custom Configuration Guide for more information on Assistants Config:\r\n# https://www.librechat.ai/docs/configuration/librechat_yaml/object_structure/assistants_endpoint\r\n","column":18,"line":152,"name":null,"position":6068,"snippet":" 150 |   #   capabilities: [\"code_interpreter\", \"retriev ...\n 151 |   agents:\n 152 |     (optional) Maximum recursion depth for agents ...\n 153 |     recursionLimit: 50\n-------------------------^\n 154 |     (optional) Disable the builder interface for  ...\n 155 |     disableBuilder: true"},"message":"Config file YAML format is invalid: bad indentation of a mapping entry (153:19)\n\n 150 |   #   capabilities: [\"code_interpreter\", \"retriev ...\n 151 |   agents:\n 152 |     (optional) Maximum recursion depth for agents ...\n 153 |     recursionLimit: 50\n-------------------------^\n 154 |     (optional) Disable the builder interface for  ...\n 155 |     disableBuilder: true","name":"YAMLException","reason":"bad indentation of a mapping entry","stack":"YAMLException: bad indentation of a mapping entry (153:19)\n\n 150 |   #   capabilities: [\"code_interpreter\", \"retriev ...\n 151 |   agents:\n 152 |     (optional) Maximum recursion depth for agents ...\n 153 |     recursionLimit: 50\n-------------------------^\n 154 |     (optional) Disable the builder interface for  ...\n 155 |     disableBuilder: true\n    at generateError (/app/node_modules/js-yaml/lib/loader.js:183:10)\n    at throwError (/app/node_modules/js-yaml/lib/loader.js:187:9)\n    at readBlockMapping (/app/node_modules/js-yaml/lib/loader.js:1182:7)\n    at composeNode (/app/node_modules/js-yaml/lib/loader.js:1441:12)\n    at readBlockMapping (/app/node_modules/js-yaml/lib/loader.js:1164:11)\n    at composeNode (/app/node_modules/js-yaml/lib/loader.js:1441:12)\n    at readDocument (/app/node_modules/js-yaml/lib/loader.js:1625:3)\n    at loadDocuments (/app/node_modules/js-yaml/lib/loader.js:1688:5)\n    at Object.load (/app/node_modules/js-yaml/lib/loader.js:1714:19)\n    at loadYaml (/app/api/utils/loadYaml.js:7:17)"}
{"level":"error","mark":{"buffer":"# For more information, see the Configuration Guide:\r\n# https://www.librechat.ai/docs/configuration/librechat_yaml\r\n\r\n# Configuration version (required)\r\nversion: 1.2.1\r\n\r\n# Cache settings: Set to true to enable caching\r\ncache: true\r\n\r\n# Custom interface configuration\r\ninterface:\r\n  # Privacy policy settings\r\n  privacyPolicy:\r\n    externalUrl: 'https://librechat.ai/privacy-policy'\r\n    openNewTab: true\r\n\r\n  # Terms of service\r\n  termsOfService:\r\n    externalUrl: 'https://librechat.ai/tos'\r\n    openNewTab: true\r\n    modalAcceptance: true\r\n    modalTitle: \"Terms of Service for LibreChat\"\r\n    modalContent: |\r\n      # Terms and Conditions for LibreChat\r\n\r\n      *Effective Date: February 18, 2024*\r\n\r\n      Welcome to LibreChat, the informational website for the open-source AI chat platform, available at https://librechat.ai. These Terms of Service (\"Terms\") govern your use of our website and the services we offer. By accessing or using the Website, you agree to be bound by these Terms and our Privacy Policy, accessible at https://librechat.ai//privacy.\r\n\r\n      ## 1. Ownership\r\n\r\n      Upon purchasing a package from LibreChat, you are granted the right to download and use the code for accessing an admin panel for LibreChat. While you own the downloaded code, you are expressly prohibited from reselling, redistributing, or otherwise transferring the code to third parties without explicit permission from LibreChat.\r\n\r\n      ## 2. User Data\r\n\r\n      We collect personal data, such as your name, email address, and payment information, as described in our Privacy Policy. This information is collected to provide and improve our services, process transactions, and communicate with you.\r\n\r\n      ## 3. Non-Personal Data Collection\r\n\r\n      The Website uses cookies to enhance user experience, analyze site usage, and facilitate certain functionalities. By using the Website, you consent to the use of cookies in accordance with our Privacy Policy.\r\n\r\n      ## 4. Use of the Website\r\n\r\n      You agree to use the Website only for lawful purposes and in a manner that does not infringe the rights of, restrict, or inhibit anyone else's use and enjoyment of the Website. Prohibited behavior includes harassing or causing distress or inconvenience to any person, transmitting obscene or offensive content, or disrupting the normal flow of dialogue within the Website.\r\n\r\n      ## 5. Governing Law\r\n\r\n      These Terms shall be governed by and construed in accordance with the laws of the United States, without giving effect to any principles of conflicts of law.\r\n\r\n      ## 6. Changes to the Terms\r\n\r\n      We reserve the right to modify these Terms at any time. We will notify users of any changes by email. Your continued use of the Website after such changes have been notified will constitute your consent to such changes.\r\n\r\n      ## 7. Contact Information\r\n\r\n      If you have any questions about these Terms, please contact us at contact@librechat.ai.\r\n\r\n      By using the Website, you acknowledge that you have read these Terms of Service and agree to be bound by them.\r\n\r\n  endpointsMenu: true\r\n  modelSelect: true\r\n  parameters: true\r\n  sidePanel: true\r\n  presets: true\r\n  prompts: true\r\n  bookmarks: true\r\n  multiConvo: true\r\n  agents: true\r\n\r\n# Example Registration Object Structure (optional)\r\nregistration:\r\n  socialLogins: ['github', 'google', 'discord', 'openid', 'facebook']\r\n  # allowedDomains:\r\n  # - \"gmail.com\"\r\n\r\n# speech:\r\n#   tts:\r\n#     openai:\r\n#       url: ''\r\n#       apiKey: '${TTS_API_KEY}'\r\n#       model: ''\r\n#       voices: ['']\r\n\r\n#  \r\n#   stt:\r\n#     openai:\r\n#       url: ''\r\n#       apiKey: '${STT_API_KEY}'\r\n#       model: ''\r\n\r\n# rateLimits:\r\n#   fileUploads:\r\n#     ipMax: 100\r\n#     ipWindowInMinutes: 60  # Rate limit window for file uploads per IP\r\n#     userMax: 50\r\n#     userWindowInMinutes: 60  # Rate limit window for file uploads per user\r\n#   conversationsImport:\r\n#     ipMax: 100\r\n#     ipWindowInMinutes: 60  # Rate limit window for conversation imports per IP\r\n#     userMax: 50\r\n#     userWindowInMinutes: 60  # Rate limit window for conversation imports per user\r\n\r\n# Example Actions Object Structure\r\nactions:\r\n  allowedDomains:\r\n    - \"swapi.dev\"\r\n    - \"librechat.ai\"\r\n    - \"google.com\"\r\n\r\n# Example MCP Servers Object Structure\r\nmcpServers:\r\n  everything:\r\n    # type: sse # type can optionally be omitted\r\n    url: http://localhost:3001/sse\r\n  puppeteer:\r\n    type: stdio\r\n    command: npx\r\n    args:\r\n      - -y\r\n      - \"@modelcontextprotocol/server-puppeteer\"\r\n  filesystem:\r\n    # type: stdio\r\n    command: npx\r\n    args:\r\n      - -y\r\n      - \"@modelcontextprotocol/server-filesystem\"\r\n      - /home/user/LibreChat/\r\n    iconPath: /home/user/LibreChat/client/public/assets/logo.svg\r\n  mcp-obsidian:\r\n    command: npx\r\n    args:\r\n      - -y\r\n      - \"mcp-obsidian\"\r\n      - /path/to/obsidian/vault\r\n\r\n# Definition of custom endpoints\r\nendpoints:\r\n  # assistants:\r\n  #   disableBuilder: false # Disable Assistants Builder Interface by setting to `true`\r\n  #   pollIntervalMs: 3000  # Polling interval for checking assistant updates\r\n  #   timeoutMs: 180000  # Timeout for assistant operations\r\n  #   # Should only be one or the other, either `supportedIds` or `excludedIds`\r\n  #   supportedIds: [\"asst_supportedAssistantId1\", \"asst_supportedAssistantId2\"]\r\n  #   # excludedIds: [\"asst_excludedAssistantId\"]\r\n  #   Only show assistants that the user created or that were created externally (e.g. in Assistants playground).\r\n  #   # privateAssistants: false # Does not work with `supportedIds` or `excludedIds`\r\n  #   # (optional) Models that support retrieval, will default to latest known OpenAI models that support the feature\r\n  #   retrievalModels: [\"gpt-4-turbo-preview\"]\r\n  #   # (optional) Assistant Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.\r\n  #   capabilities: [\"code_interpreter\", \"retrieval\", \"actions\", \"tools\", \"image_vision\"]\r\n  agents:\r\n    (optional) Maximum recursion depth for agents, defaults to 25\r\n    recursionLimit: 50\r\n    (optional) Disable the builder interface for agents\r\n    disableBuilder: true\r\n    (optional) Agent Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.\r\n    capabilities: []\r\n  custom:\r\n    # Groq Example\r\n    - name: 'groq'\r\n      apiKey: '${GROQ_API_KEY}'\r\n      baseURL: 'https://api.groq.com/openai/v1/'\r\n      models:\r\n        default:\r\n          [\r\n            'llama3-70b-8192',\r\n            'llama3-8b-8192',\r\n            'llama2-70b-4096',\r\n            'mixtral-8x7b-32768',\r\n            'gemma-7b-it',\r\n          ]\r\n        fetch: false\r\n      titleConvo: true\r\n      titleModel: 'mixtral-8x7b-32768'\r\n      modelDisplayLabel: 'groq'\r\n\r\n    # Mistral AI Example\r\n    - name: 'Mistral' # Unique name for the endpoint\r\n      # For `apiKey` and `baseURL`, you can use environment variables that you define.\r\n      # recommended environment variables:\r\n      apiKey: '${MISTRAL_API_KEY}'\r\n      baseURL: 'https://api.mistral.ai/v1'\r\n\r\n      # Models configuration\r\n      models:\r\n        # List of default models to use. At least one value is required.\r\n        default: ['mistral-tiny', 'mistral-small', 'mistral-medium']\r\n        # Fetch option: Set to true to fetch models from API.\r\n        fetch: true # Defaults to false.\r\n\r\n      # Optional configurations\r\n\r\n      # Title Conversation setting\r\n      titleConvo: true # Set to true to enable title conversation\r\n\r\n      # Title Method: Choose between \"completion\" or \"functions\".\r\n      # titleMethod: \"completion\"  # Defaults to \"completion\" if omitted.\r\n\r\n      # Title Model: Specify the model to use for titles.\r\n      titleModel: 'mistral-tiny' # Defaults to \"gpt-3.5-turbo\" if omitted.\r\n\r\n      # Summarize setting: Set to true to enable summarization.\r\n      # summarize: false\r\n\r\n      # Summary Model: Specify the model to use if summarization is enabled.\r\n      # summaryModel: \"mistral-tiny\"  # Defaults to \"gpt-3.5-turbo\" if omitted.\r\n\r\n      # Force Prompt setting: If true, sends a `prompt` parameter instead of `messages`.\r\n      # forcePrompt: false\r\n\r\n      # The label displayed for the AI model in messages.\r\n      modelDisplayLabel: 'Mistral' # Default is \"AI\" when not set.\r\n\r\n      # Add additional parameters to the request. Default params will be overwritten.\r\n      # addParams:\r\n      # safe_prompt: true # This field is specific to Mistral AI: https://docs.mistral.ai/api/\r\n\r\n      # Drop Default params parameters from the request. See default params in guide linked below.\r\n      # NOTE: For Mistral, it is necessary to drop the following parameters or you will encounter a 422 Error:\r\n      dropParams: ['stop', 'user', 'frequency_penalty', 'presence_penalty']\r\n\r\n    # OpenRouter Example\r\n    - name: 'OpenRouter'\r\n      # For `apiKey` and `baseURL`, you can use environment variables that you define.\r\n      # recommended environment variables:\r\n      # Known issue: you should not use `OPENROUTER_API_KEY` as it will then override the `openAI` endpoint to use OpenRouter as well.\r\n      apiKey: '${OPENROUTER_KEY}'\r\n      baseURL: 'https://openrouter.ai/api/v1'\r\n      models:\r\n        default: ['meta-llama/llama-3-70b-instruct']\r\n        fetch: true\r\n      titleConvo: true\r\n      titleModel: 'meta-llama/llama-3-70b-instruct'\r\n      # Recommended: Drop the stop parameter from the request as Openrouter models use a variety of stop tokens.\r\n      dropParams: ['stop']\r\n      modelDisplayLabel: 'OpenRouter'\r\n      \r\n    # Portkey AI Example\r\n    - name: \"Portkey\"\r\n      apiKey: \"dummy\"  \r\n      baseURL: 'https://api.portkey.ai/v1'\r\n      headers:\r\n          x-portkey-api-key: [REDACTED]          x-portkey-virtual-key: '${PORTKEY_OPENAI_VIRTUAL_KEY}'\r\n      models:\r\n          default: ['gpt-4o-mini', 'gpt-4o', 'chatgpt-4o-latest']\r\n          fetch: true\r\n      titleConvo: true\r\n      titleModel: 'current_model'\r\n      summarize: false\r\n      summaryModel: 'current_model'\r\n      forcePrompt: false\r\n      modelDisplayLabel: 'Portkey'\r\n      iconURL: https://images.crunchbase.com/image/upload/c_pad,f_auto,q_auto:eco,dpr_1/rjqy7ghvjoiu4cd1xjbf\r\n# fileConfig:\r\n#   endpoints:\r\n#     assistants:\r\n#       fileLimit: 5\r\n#       fileSizeLimit: 10  # Maximum size for an individual file in MB\r\n#       totalSizeLimit: 50  # Maximum total size for all files in a single request in MB\r\n#       supportedMimeTypes:\r\n#         - \"image/.*\"\r\n#         - \"application/pdf\"\r\n#     openAI:\r\n#       disabled: true  # Disables file uploading to the OpenAI endpoint\r\n#     default:\r\n#       totalSizeLimit: 20\r\n#     YourCustomEndpointName:\r\n#       fileLimit: 2\r\n#       fileSizeLimit: 5\r\n#   serverFileSizeLimit: 100  # Global server file size limit in MB\r\n#   avatarSizeLimit: 2  # Limit for user avatar image size in MB\r\n# See the Custom Configuration Guide for more information on Assistants Config:\r\n# https://www.librechat.ai/docs/configuration/librechat_yaml/object_structure/assistants_endpoint\r\n","column":18,"line":152,"name":null,"position":6068,"snippet":" 150 |   #   capabilities: [\"code_interpreter\", \"retriev ...\n 151 |   agents:\n 152 |     (optional) Maximum recursion depth for agents ...\n 153 |     recursionLimit: 50\n-------------------------^\n 154 |     (optional) Disable the builder interface for  ...\n 155 |     disableBuilder: true"},"message":"Config file YAML format is invalid: bad indentation of a mapping entry (153:19)\n\n 150 |   #   capabilities: [\"code_interpreter\", \"retriev ...\n 151 |   agents:\n 152 |     (optional) Maximum recursion depth for agents ...\n 153 |     recursionLimit: 50\n-------------------------^\n 154 |     (optional) Disable the builder interface for  ...\n 155 |     disableBuilder: true","name":"YAMLException","reason":"bad indentation of a mapping entry","stack":"YAMLException: bad indentation of a mapping entry (153:19)\n\n 150 |   #   capabilities: [\"code_interpreter\", \"retriev ...\n 151 |   agents:\n 152 |     (optional) Maximum recursion depth for agents ...\n 153 |     recursionLimit: 50\n-------------------------^\n 154 |     (optional) Disable the builder interface for  ...\n 155 |     disableBuilder: true\n    at generateError (/app/node_modules/js-yaml/lib/loader.js:183:10)\n    at throwError (/app/node_modules/js-yaml/lib/loader.js:187:9)\n    at readBlockMapping (/app/node_modules/js-yaml/lib/loader.js:1182:7)\n    at composeNode (/app/node_modules/js-yaml/lib/loader.js:1441:12)\n    at readBlockMapping (/app/node_modules/js-yaml/lib/loader.js:1164:11)\n    at composeNode (/app/node_modules/js-yaml/lib/loader.js:1441:12)\n    at readDocument (/app/node_modules/js-yaml/lib/loader.js:1625:3)\n    at loadDocuments (/app/node_modules/js-yaml/lib/loader.js:1688:5)\n    at Object.load (/app/node_modules/js-yaml/lib/loader.js:1714:19)\n    at loadYaml (/app/api/utils/loadYaml.js:7:17)"}
{"level":"error","mark":{"buffer":"# For more information, see the Configuration Guide:\r\n# https://www.librechat.ai/docs/configuration/librechat_yaml\r\n\r\n# Configuration version (required)\r\nversion: 1.2.1\r\n\r\n# Cache settings: Set to true to enable caching\r\ncache: true\r\n\r\n# Custom interface configuration\r\ninterface:\r\n  # Privacy policy settings\r\n  privacyPolicy:\r\n    externalUrl: 'https://librechat.ai/privacy-policy'\r\n    openNewTab: true\r\n\r\n  # Terms of service\r\n  termsOfService:\r\n    externalUrl: 'https://librechat.ai/tos'\r\n    openNewTab: true\r\n    modalAcceptance: true\r\n    modalTitle: \"Terms of Service for LibreChat\"\r\n    modalContent: |\r\n      # Terms and Conditions for LibreChat\r\n\r\n      *Effective Date: February 18, 2024*\r\n\r\n      Welcome to LibreChat, the informational website for the open-source AI chat platform, available at https://librechat.ai. These Terms of Service (\"Terms\") govern your use of our website and the services we offer. By accessing or using the Website, you agree to be bound by these Terms and our Privacy Policy, accessible at https://librechat.ai//privacy.\r\n\r\n      ## 1. Ownership\r\n\r\n      Upon purchasing a package from LibreChat, you are granted the right to download and use the code for accessing an admin panel for LibreChat. While you own the downloaded code, you are expressly prohibited from reselling, redistributing, or otherwise transferring the code to third parties without explicit permission from LibreChat.\r\n\r\n      ## 2. User Data\r\n\r\n      We collect personal data, such as your name, email address, and payment information, as described in our Privacy Policy. This information is collected to provide and improve our services, process transactions, and communicate with you.\r\n\r\n      ## 3. Non-Personal Data Collection\r\n\r\n      The Website uses cookies to enhance user experience, analyze site usage, and facilitate certain functionalities. By using the Website, you consent to the use of cookies in accordance with our Privacy Policy.\r\n\r\n      ## 4. Use of the Website\r\n\r\n      You agree to use the Website only for lawful purposes and in a manner that does not infringe the rights of, restrict, or inhibit anyone else's use and enjoyment of the Website. Prohibited behavior includes harassing or causing distress or inconvenience to any person, transmitting obscene or offensive content, or disrupting the normal flow of dialogue within the Website.\r\n\r\n      ## 5. Governing Law\r\n\r\n      These Terms shall be governed by and construed in accordance with the laws of the United States, without giving effect to any principles of conflicts of law.\r\n\r\n      ## 6. Changes to the Terms\r\n\r\n      We reserve the right to modify these Terms at any time. We will notify users of any changes by email. Your continued use of the Website after such changes have been notified will constitute your consent to such changes.\r\n\r\n      ## 7. Contact Information\r\n\r\n      If you have any questions about these Terms, please contact us at contact@librechat.ai.\r\n\r\n      By using the Website, you acknowledge that you have read these Terms of Service and agree to be bound by them.\r\n\r\n  endpointsMenu: true\r\n  modelSelect: true\r\n  parameters: true\r\n  sidePanel: true\r\n  presets: true\r\n  prompts: true\r\n  bookmarks: true\r\n  multiConvo: true\r\n  agents: true\r\n\r\n# Example Registration Object Structure (optional)\r\nregistration:\r\n  socialLogins: ['github', 'google', 'discord', 'openid', 'facebook']\r\n  # allowedDomains:\r\n  # - \"gmail.com\"\r\n\r\n# speech:\r\n#   tts:\r\n#     openai:\r\n#       url: ''\r\n#       apiKey: '${TTS_API_KEY}'\r\n#       model: ''\r\n#       voices: ['']\r\n\r\n#  \r\n#   stt:\r\n#     openai:\r\n#       url: ''\r\n#       apiKey: '${STT_API_KEY}'\r\n#       model: ''\r\n\r\n# rateLimits:\r\n#   fileUploads:\r\n#     ipMax: 100\r\n#     ipWindowInMinutes: 60  # Rate limit window for file uploads per IP\r\n#     userMax: 50\r\n#     userWindowInMinutes: 60  # Rate limit window for file uploads per user\r\n#   conversationsImport:\r\n#     ipMax: 100\r\n#     ipWindowInMinutes: 60  # Rate limit window for conversation imports per IP\r\n#     userMax: 50\r\n#     userWindowInMinutes: 60  # Rate limit window for conversation imports per user\r\n\r\n# Example Actions Object Structure\r\nactions:\r\n  allowedDomains:\r\n    - \"swapi.dev\"\r\n    - \"librechat.ai\"\r\n    - \"google.com\"\r\n\r\n# Example MCP Servers Object Structure\r\nmcpServers:\r\n  everything:\r\n    # type: sse # type can optionally be omitted\r\n    url: http://localhost:3001/sse\r\n  puppeteer:\r\n    type: stdio\r\n    command: npx\r\n    args:\r\n      - -y\r\n      - \"@modelcontextprotocol/server-puppeteer\"\r\n  filesystem:\r\n    # type: stdio\r\n    command: npx\r\n    args:\r\n      - -y\r\n      - \"@modelcontextprotocol/server-filesystem\"\r\n      - /home/user/LibreChat/\r\n    iconPath: /home/user/LibreChat/client/public/assets/logo.svg\r\n  mcp-obsidian:\r\n    command: npx\r\n    args:\r\n      - -y\r\n      - \"mcp-obsidian\"\r\n      - /path/to/obsidian/vault\r\n\r\n# Definition of custom endpoints\r\nendpoints:\r\n  # assistants:\r\n  #   disableBuilder: false # Disable Assistants Builder Interface by setting to `true`\r\n  #   pollIntervalMs: 3000  # Polling interval for checking assistant updates\r\n  #   timeoutMs: 180000  # Timeout for assistant operations\r\n  #   # Should only be one or the other, either `supportedIds` or `excludedIds`\r\n  #   supportedIds: [\"asst_supportedAssistantId1\", \"asst_supportedAssistantId2\"]\r\n  #   # excludedIds: [\"asst_excludedAssistantId\"]\r\n  #   Only show assistants that the user created or that were created externally (e.g. in Assistants playground).\r\n  #   # privateAssistants: false # Does not work with `supportedIds` or `excludedIds`\r\n  #   # (optional) Models that support retrieval, will default to latest known OpenAI models that support the feature\r\n  #   retrievalModels: [\"gpt-4-turbo-preview\"]\r\n  #   # (optional) Assistant Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.\r\n  #   capabilities: [\"code_interpreter\", \"retrieval\", \"actions\", \"tools\", \"image_vision\"]\r\n  agents:\r\n    (optional) Maximum recursion depth for agents, defaults to 25\r\n    recursionLimit: 50\r\n    (optional) Disable the builder interface for agents\r\n    disableBuilder: true\r\n    (optional) Agent Capabilities available to all users. Omit the ones you wish to exclude. Defaults to list below.\r\n    capabilities: []\r\n  custom:\r\n    # Groq Example\r\n    - name: 'groq'\r\n      apiKey: '${GROQ_API_KEY}'\r\n      baseURL: 'https://api.groq.com/openai/v1/'\r\n      models:\r\n        default:\r\n          [\r\n            'llama3-70b-8192',\r\n            'llama3-8b-8192',\r\n            'llama2-70b-4096',\r\n            'mixtral-8x7b-32768',\r\n            'gemma-7b-it',\r\n          ]\r\n        fetch: false\r\n      titleConvo: true\r\n      titleModel: 'mixtral-8x7b-32768'\r\n      modelDisplayLabel: 'groq'\r\n\r\n    # Mistral AI Example\r\n    - name: 'Mistral' # Unique name for the endpoint\r\n      # For `apiKey` and `baseURL`, you can use environment variables that you define.\r\n      # recommended environment variables:\r\n      apiKey: '${MISTRAL_API_KEY}'\r\n      baseURL: 'https://api.mistral.ai/v1'\r\n\r\n      # Models configuration\r\n      models:\r\n        # List of default models to use. At least one value is required.\r\n        default: ['mistral-tiny', 'mistral-small', 'mistral-medium']\r\n        # Fetch option: Set to true to fetch models from API.\r\n        fetch: true # Defaults to false.\r\n\r\n      # Optional configurations\r\n\r\n      # Title Conversation setting\r\n      titleConvo: true # Set to true to enable title conversation\r\n\r\n      # Title Method: Choose between \"completion\" or \"functions\".\r\n      # titleMethod: \"completion\"  # Defaults to \"completion\" if omitted.\r\n\r\n      # Title Model: Specify the model to use for titles.\r\n      titleModel: 'mistral-tiny' # Defaults to \"gpt-3.5-turbo\" if omitted.\r\n\r\n      # Summarize setting: Set to true to enable summarization.\r\n      # summarize: false\r\n\r\n      # Summary Model: Specify the model to use if summarization is enabled.\r\n      # summaryModel: \"mistral-tiny\"  # Defaults to \"gpt-3.5-turbo\" if omitted.\r\n\r\n      # Force Prompt setting: If true, sends a `prompt` parameter instead of `messages`.\r\n      # forcePrompt: false\r\n\r\n      # The label displayed for the AI model in messages.\r\n      modelDisplayLabel: 'Mistral' # Default is \"AI\" when not set.\r\n\r\n      # Add additional parameters to the request. Default params will be overwritten.\r\n      # addParams:\r\n      # safe_prompt: true # This field is specific to Mistral AI: https://docs.mistral.ai/api/\r\n\r\n      # Drop Default params parameters from the request. See default params in guide linked below.\r\n      # NOTE: For Mistral, it is necessary to drop the following parameters or you will encounter a 422 Error:\r\n      dropParams: ['stop', 'user', 'frequency_penalty', 'presence_penalty']\r\n\r\n    # OpenRouter Example\r\n    - name: 'OpenRouter'\r\n      # For `apiKey` and `baseURL`, you can use environment variables that you define.\r\n      # recommended environment variables:\r\n      # Known issue: you should not use `OPENROUTER_API_KEY` as it will then override the `openAI` endpoint to use OpenRouter as well.\r\n      apiKey: '${OPENROUTER_KEY}'\r\n      baseURL: 'https://openrouter.ai/api/v1'\r\n      models:\r\n        default: ['meta-llama/llama-3-70b-instruct']\r\n        fetch: true\r\n      titleConvo: true\r\n      titleModel: 'meta-llama/llama-3-70b-instruct'\r\n      # Recommended: Drop the stop parameter from the request as Openrouter models use a variety of stop tokens.\r\n      dropParams: ['stop']\r\n      modelDisplayLabel: 'OpenRouter'\r\n      \r\n    # Portkey AI Example\r\n    - name: \"Portkey\"\r\n      apiKey: \"dummy\"  \r\n      baseURL: 'https://api.portkey.ai/v1'\r\n      headers:\r\n          x-portkey-api-key: [REDACTED]          x-portkey-virtual-key: '${PORTKEY_OPENAI_VIRTUAL_KEY}'\r\n      models:\r\n          default: ['gpt-4o-mini', 'gpt-4o', 'chatgpt-4o-latest']\r\n          fetch: true\r\n      titleConvo: true\r\n      titleModel: 'current_model'\r\n      summarize: false\r\n      summaryModel: 'current_model'\r\n      forcePrompt: false\r\n      modelDisplayLabel: 'Portkey'\r\n      iconURL: https://images.crunchbase.com/image/upload/c_pad,f_auto,q_auto:eco,dpr_1/rjqy7ghvjoiu4cd1xjbf\r\n# fileConfig:\r\n#   endpoints:\r\n#     assistants:\r\n#       fileLimit: 5\r\n#       fileSizeLimit: 10  # Maximum size for an individual file in MB\r\n#       totalSizeLimit: 50  # Maximum total size for all files in a single request in MB\r\n#       supportedMimeTypes:\r\n#         - \"image/.*\"\r\n#         - \"application/pdf\"\r\n#     openAI:\r\n#       disabled: true  # Disables file uploading to the OpenAI endpoint\r\n#     default:\r\n#       totalSizeLimit: 20\r\n#     YourCustomEndpointName:\r\n#       fileLimit: 2\r\n#       fileSizeLimit: 5\r\n#   serverFileSizeLimit: 100  # Global server file size limit in MB\r\n#   avatarSizeLimit: 2  # Limit for user avatar image size in MB\r\n# See the Custom Configuration Guide for more information on Assistants Config:\r\n# https://www.librechat.ai/docs/configuration/librechat_yaml/object_structure/assistants_endpoint\r\n","column":18,"line":152,"name":null,"position":6068,"snippet":" 150 |   #   capabilities: [\"code_interpreter\", \"retriev ...\n 151 |   agents:\n 152 |     (optional) Maximum recursion depth for agents ...\n 153 |     recursionLimit: 50\n-------------------------^\n 154 |     (optional) Disable the builder interface for  ...\n 155 |     disableBuilder: true"},"message":"Config file YAML format is invalid: bad indentation of a mapping entry (153:19)\n\n 150 |   #   capabilities: [\"code_interpreter\", \"retriev ...\n 151 |   agents:\n 152 |     (optional) Maximum recursion depth for agents ...\n 153 |     recursionLimit: 50\n-------------------------^\n 154 |     (optional) Disable the builder interface for  ...\n 155 |     disableBuilder: true","name":"YAMLException","reason":"bad indentation of a mapping entry","stack":"YAMLException: bad indentation of a mapping entry (153:19)\n\n 150 |   #   capabilities: [\"code_interpreter\", \"retriev ...\n 151 |   agents:\n 152 |     (optional) Maximum recursion depth for agents ...\n 153 |     recursionLimit: 50\n-------------------------^\n 154 |     (optional) Disable the builder interface for  ...\n 155 |     disableBuilder: true\n    at generateError (/app/node_modules/js-yaml/lib/loader.js:183:10)\n    at throwError (/app/node_modules/js-yaml/lib/loader.js:187:9)\n    at readBlockMapping (/app/node_modules/js-yaml/lib/loader.js:1182:7)\n    at composeNode (/app/node_modules/js-yaml/lib/loader.js:1441:12)\n    at readBlockMapping (/app/node_modules/js-yaml/lib/loader.js:1164:11)\n    at composeNode (/app/node_modules/js-yaml/lib/loader.js:1441:12)\n    at readDocument (/app/node_modules/js-yaml/lib/loader.js:1625:3)\n    at loadDocuments (/app/node_modules/js-yaml/lib/loader.js:1688:5)\n    at Object.load (/app/node_modules/js-yaml/lib/loader.js:1714:19)\n    at loadYaml (/app/api/utils/loadYaml.js:7:17)"}
{"level":"error","message":"[MCP][everything] Connection failed: SSE error: {}","stack":"Error: SSE error: {}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.scheduleReconnect_fn (/app/node_modules/eventsource/dist/index.cjs:194:53)\n    at /app/node_modules/eventsource/dist/index.cjs:47:174\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP][everything] Connection failed: SSE error: {}","stack":"Error: SSE error: {}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.scheduleReconnect_fn (/app/node_modules/eventsource/dist/index.cjs:194:53)\n    at /app/node_modules/eventsource/dist/index.cjs:47:174\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP][everything] Connection failed: SSE error: {}","stack":"Error: SSE error: {}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.scheduleReconnect_fn (/app/node_modules/eventsource/dist/index.cjs:194:53)\n    at /app/node_modules/eventsource/dist/index.cjs:47:174\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP][everything] Failed after 3 attempts"}
{"level":"error","message":"[MCP][everything] Initialization failed SSE error: {}","stack":"Error: SSE error: {}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.scheduleReconnect_fn (/app/node_modules/eventsource/dist/index.cjs:194:53)\n    at /app/node_modules/eventsource/dist/index.cjs:47:174\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP][puppeteer] Connection failed: Connection timeout","stack":"Error: Connection timeout\n    at Timeout._onTimeout (file:///app/packages/mcp/dist/index.es.js:1:85241)\n    at listOnTimeout (node:internal/timers:581:17)\n    at process.processTimers (node:internal/timers:519:7)"}
{"level":"error","message":"[MCP][filesystem] Connection failed: Connection timeout","stack":"Error: Connection timeout\n    at Timeout._onTimeout (file:///app/packages/mcp/dist/index.es.js:1:85241)\n    at listOnTimeout (node:internal/timers:581:17)\n    at process.processTimers (node:internal/timers:519:7)"}
{"level":"error","message":"[MCP][mcp-obsidian] Connection failed: Connection timeout","stack":"Error: Connection timeout\n    at Timeout._onTimeout (file:///app/packages/mcp/dist/index.es.js:1:85241)\n    at listOnTimeout (node:internal/timers:581:17)\n    at process.processTimers (node:internal/timers:519:7)"}
{"code":-1,"level":"error","message":"[MCP][puppeteer] Connection failed: MCP error -1: Connection closed","stack":"Error: MCP error -1: Connection closed\n    at Yr._onclose (file:///app/packages/mcp/dist/index.es.js:1:67087)\n    at _transport.onclose (file:///app/packages/mcp/dist/index.es.js:1:66692)\n    at ChildProcess.<anonymous> (file:///app/packages/mcp/dist/index.es.js:1:78353)\n    at ChildProcess.emit (node:events:518:28)\n    at maybeClose (node:internal/child_process:1104:16)\n    at ChildProcess._handle.onexit (node:internal/child_process:304:5)"}
{"code":-1,"level":"error","message":"[MCP][mcp-obsidian] Connection failed: MCP error -1: Connection closed","stack":"Error: MCP error -1: Connection closed\n    at Yr._onclose (file:///app/packages/mcp/dist/index.es.js:1:67087)\n    at _transport.onclose (file:///app/packages/mcp/dist/index.es.js:1:66692)\n    at ChildProcess.<anonymous> (file:///app/packages/mcp/dist/index.es.js:1:78353)\n    at ChildProcess.emit (node:events:518:28)\n    at maybeClose (node:internal/child_process:1104:16)\n    at ChildProcess._handle.onexit (node:internal/child_process:304:5)"}
{"code":-1,"level":"error","message":"[MCP][filesystem] Connection failed: MCP error -1: Connection closed","stack":"Error: MCP error -1: Connection closed\n    at Yr._onclose (file:///app/packages/mcp/dist/index.es.js:1:67087)\n    at _transport.onclose (file:///app/packages/mcp/dist/index.es.js:1:66692)\n    at ChildProcess.<anonymous> (file:///app/packages/mcp/dist/index.es.js:1:78353)\n    at ChildProcess.emit (node:events:518:28)\n    at maybeClose (node:internal/child_process:1104:16)\n    at Socket.<anonymous> (node:internal/child_process:456:11)\n    at Socket.emit (node:events:518:28)\n    at Pipe.<anonymous> (node:net:343:12)"}
{"level":"error","message":"[MCP][puppeteer] Connection failed: Connection timeout","stack":"Error: Connection timeout\n    at Timeout._onTimeout (file:///app/packages/mcp/dist/index.es.js:1:85241)\n    at listOnTimeout (node:internal/timers:581:17)\n    at process.processTimers (node:internal/timers:519:7)"}
{"level":"error","message":"[MCP][puppeteer] Failed after 3 attempts"}
{"level":"error","message":"[MCP][puppeteer] Initialization failed Connection timeout","stack":"Error: Connection timeout\n    at Timeout._onTimeout (file:///app/packages/mcp/dist/index.es.js:1:85241)\n    at listOnTimeout (node:internal/timers:581:17)\n    at process.processTimers (node:internal/timers:519:7)"}
{"level":"error","message":"[MCP][mcp-obsidian] Connection failed: Connection timeout","stack":"Error: Connection timeout\n    at Timeout._onTimeout (file:///app/packages/mcp/dist/index.es.js:1:85241)\n    at listOnTimeout (node:internal/timers:581:17)\n    at process.processTimers (node:internal/timers:519:7)"}
{"level":"error","message":"[MCP][mcp-obsidian] Failed after 3 attempts"}
{"level":"error","message":"[MCP][mcp-obsidian] Initialization failed Connection timeout","stack":"Error: Connection timeout\n    at Timeout._onTimeout (file:///app/packages/mcp/dist/index.es.js:1:85241)\n    at listOnTimeout (node:internal/timers:581:17)\n    at process.processTimers (node:internal/timers:519:7)"}
{"level":"error","message":"[MCP][filesystem] Connection failed: Connection timeout","stack":"Error: Connection timeout\n    at Timeout._onTimeout (file:///app/packages/mcp/dist/index.es.js:1:85241)\n    at listOnTimeout (node:internal/timers:581:17)\n    at process.processTimers (node:internal/timers:519:7)"}
{"level":"error","message":"[MCP][filesystem] Failed after 3 attempts"}
{"level":"error","message":"[MCP][filesystem] Initialization failed Connection timeout","stack":"Error: Connection timeout\n    at Timeout._onTimeout (file:///app/packages/mcp/dist/index.es.js:1:85241)\n    at listOnTimeout (node:internal/timers:581:17)\n    at process.processTimers (node:internal/timers:519:7)"}
{"level":"error","message":"[MCP] No servers initialized"}
{"code":"ERR_INVALID_URL","input":"/api/auth/refresh","level":"error","message":"Failed to fetch models from Mistral API\nSomething happened in setting up the request. Error message:\n Invalid URL","stack":"TypeError: Invalid URL\n    at new URL (node:internal/url:806:29)\n    at dispatchHttpRequest (/app/node_modules/axios/dist/node/axios.cjs:2770:20)\n    at /app/node_modules/axios/dist/node/axios.cjs:2690:5\n    at new Promise (<anonymous>)\n    at wrapAsync (/app/node_modules/axios/dist/node/axios.cjs:2670:10)\n    at http (/app/node_modules/axios/dist/node/axios.cjs:2708:10)\n    at Axios.dispatchRequest (/app/node_modules/axios/dist/node/axios.cjs:4135:10)\n    at Axios._request (/app/node_modules/axios/dist/node/axios.cjs:4415:33)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4282:25)\n    at Axios.httpMethod [as post] (/app/node_modules/axios/dist/node/axios.cjs:4454:19)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4287:41)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4287:41)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async fetchModels (/app/api/server/services/ModelService.js:84:17)\n    at async Promise.all (index 0)\n    at async loadConfigModels (/app/api/server/services/Config/loadConfigModels.js:95:23)\n    at async loadModels (/app/api/server/controllers/ModelController.js:30:30)\n    at async modelController (/app/api/server/controllers/ModelController.js:39:23)"}
{"code":"ERR_INVALID_URL","input":"/api/auth/refresh","level":"error","message":"Failed to fetch models from Portkey API\nSomething happened in setting up the request. Error message:\n Invalid URL","stack":"TypeError: Invalid URL\n    at new URL (node:internal/url:806:29)\n    at dispatchHttpRequest (/app/node_modules/axios/dist/node/axios.cjs:2770:20)\n    at /app/node_modules/axios/dist/node/axios.cjs:2690:5\n    at new Promise (<anonymous>)\n    at wrapAsync (/app/node_modules/axios/dist/node/axios.cjs:2670:10)\n    at http (/app/node_modules/axios/dist/node/axios.cjs:2708:10)\n    at Axios.dispatchRequest (/app/node_modules/axios/dist/node/axios.cjs:4135:10)\n    at Axios._request (/app/node_modules/axios/dist/node/axios.cjs:4415:33)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4282:25)\n    at Axios.httpMethod [as post] (/app/node_modules/axios/dist/node/axios.cjs:4454:19)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4287:41)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4287:41)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async fetchModels (/app/api/server/services/ModelService.js:84:17)\n    at async Promise.all (index 2)\n    at async loadConfigModels (/app/api/server/services/Config/loadConfigModels.js:95:23)\n    at async loadModels (/app/api/server/controllers/ModelController.js:30:30)\n    at async modelController (/app/api/server/controllers/ModelController.js:39:23)"}
{"level":"error","message":"[MCP][everything] Connection failed: SSE error: {}","stack":"Error: SSE error: {}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.scheduleReconnect_fn (/app/node_modules/eventsource/dist/index.cjs:194:53)\n    at /app/node_modules/eventsource/dist/index.cjs:47:174\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP][everything] Connection failed: SSE error: {}","stack":"Error: SSE error: {}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.scheduleReconnect_fn (/app/node_modules/eventsource/dist/index.cjs:194:53)\n    at /app/node_modules/eventsource/dist/index.cjs:47:174\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP][everything] Connection failed: SSE error: {}","stack":"Error: SSE error: {}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.scheduleReconnect_fn (/app/node_modules/eventsource/dist/index.cjs:194:53)\n    at /app/node_modules/eventsource/dist/index.cjs:47:174\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP][everything] Failed after 3 attempts"}
{"level":"error","message":"[MCP][everything] Initialization failed SSE error: {}","stack":"Error: SSE error: {}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.scheduleReconnect_fn (/app/node_modules/eventsource/dist/index.cjs:194:53)\n    at /app/node_modules/eventsource/dist/index.cjs:47:174\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP][puppeteer] Connection failed: Connection timeout","stack":"Error: Connection timeout\n    at Timeout._onTimeout (file:///app/packages/mcp/dist/index.es.js:1:85241)\n    at listOnTimeout (node:internal/timers:581:17)\n    at process.processTimers (node:internal/timers:519:7)"}
{"level":"error","message":"[MCP][filesystem] Connection failed: Connection timeout","stack":"Error: Connection timeout\n    at Timeout._onTimeout (file:///app/packages/mcp/dist/index.es.js:1:85241)\n    at listOnTimeout (node:internal/timers:581:17)\n    at process.processTimers (node:internal/timers:519:7)"}
{"level":"error","message":"[MCP][mcp-obsidian] Connection failed: Connection timeout","stack":"Error: Connection timeout\n    at Timeout._onTimeout (file:///app/packages/mcp/dist/index.es.js:1:85241)\n    at listOnTimeout (node:internal/timers:581:17)\n    at process.processTimers (node:internal/timers:519:7)"}
{"code":-1,"level":"error","message":"[MCP][puppeteer] Connection failed: MCP error -1: Connection closed","stack":"Error: MCP error -1: Connection closed\n    at Yr._onclose (file:///app/packages/mcp/dist/index.es.js:1:67087)\n    at _transport.onclose (file:///app/packages/mcp/dist/index.es.js:1:66692)\n    at ChildProcess.<anonymous> (file:///app/packages/mcp/dist/index.es.js:1:78353)\n    at ChildProcess.emit (node:events:518:28)\n    at maybeClose (node:internal/child_process:1104:16)\n    at ChildProcess._handle.onexit (node:internal/child_process:304:5)"}
{"code":-1,"level":"error","message":"[MCP][mcp-obsidian] Connection failed: MCP error -1: Connection closed","stack":"Error: MCP error -1: Connection closed\n    at Yr._onclose (file:///app/packages/mcp/dist/index.es.js:1:67087)\n    at _transport.onclose (file:///app/packages/mcp/dist/index.es.js:1:66692)\n    at ChildProcess.<anonymous> (file:///app/packages/mcp/dist/index.es.js:1:78353)\n    at ChildProcess.emit (node:events:518:28)\n    at maybeClose (node:internal/child_process:1104:16)\n    at ChildProcess._handle.onexit (node:internal/child_process:304:5)"}
{"code":-1,"level":"error","message":"[MCP][filesystem] Connection failed: MCP error -1: Connection closed","stack":"Error: MCP error -1: Connection closed\n    at Yr._onclose (file:///app/packages/mcp/dist/index.es.js:1:67087)\n    at _transport.onclose (file:///app/packages/mcp/dist/index.es.js:1:66692)\n    at ChildProcess.<anonymous> (file:///app/packages/mcp/dist/index.es.js:1:78353)\n    at ChildProcess.emit (node:events:518:28)\n    at maybeClose (node:internal/child_process:1104:16)\n    at ChildProcess._handle.onexit (node:internal/child_process:304:5)"}
{"code":-1,"level":"error","message":"[MCP][filesystem] Connection failed: MCP error -1: Connection closed","stack":"Error: MCP error -1: Connection closed\n    at Yr._onclose (file:///app/packages/mcp/dist/index.es.js:1:67087)\n    at _transport.onclose (file:///app/packages/mcp/dist/index.es.js:1:66692)\n    at ChildProcess.<anonymous> (file:///app/packages/mcp/dist/index.es.js:1:78353)\n    at ChildProcess.emit (node:events:518:28)\n    at maybeClose (node:internal/child_process:1104:16)\n    at ChildProcess._handle.onexit (node:internal/child_process:304:5)"}
{"level":"error","message":"[MCP][filesystem] Failed after 3 attempts"}
{"code":-1,"level":"error","message":"[MCP][filesystem] Initialization failed MCP error -1: Connection closed","stack":"Error: MCP error -1: Connection closed\n    at Yr._onclose (file:///app/packages/mcp/dist/index.es.js:1:67087)\n    at _transport.onclose (file:///app/packages/mcp/dist/index.es.js:1:66692)\n    at ChildProcess.<anonymous> (file:///app/packages/mcp/dist/index.es.js:1:78353)\n    at ChildProcess.emit (node:events:518:28)\n    at maybeClose (node:internal/child_process:1104:16)\n    at ChildProcess._handle.onexit (node:internal/child_process:304:5)"}
{"code":-1,"level":"error","message":"[MCP][mcp-obsidian] Connection failed: MCP error -1: Connection closed","stack":"Error: MCP error -1: Connection closed\n    at Yr._onclose (file:///app/packages/mcp/dist/index.es.js:1:67087)\n    at _transport.onclose (file:///app/packages/mcp/dist/index.es.js:1:66692)\n    at ChildProcess.<anonymous> (file:///app/packages/mcp/dist/index.es.js:1:78353)\n    at ChildProcess.emit (node:events:518:28)\n    at maybeClose (node:internal/child_process:1104:16)\n    at ChildProcess._handle.onexit (node:internal/child_process:304:5)"}
{"level":"error","message":"[MCP][mcp-obsidian] Failed after 3 attempts"}
{"code":-1,"level":"error","message":"[MCP][mcp-obsidian] Initialization failed MCP error -1: Connection closed","stack":"Error: MCP error -1: Connection closed\n    at Yr._onclose (file:///app/packages/mcp/dist/index.es.js:1:67087)\n    at _transport.onclose (file:///app/packages/mcp/dist/index.es.js:1:66692)\n    at ChildProcess.<anonymous> (file:///app/packages/mcp/dist/index.es.js:1:78353)\n    at ChildProcess.emit (node:events:518:28)\n    at maybeClose (node:internal/child_process:1104:16)\n    at ChildProcess._handle.onexit (node:internal/child_process:304:5)"}
{"code":"ERR_INVALID_URL","input":"/api/auth/refresh","level":"error","message":"Failed to fetch models from Mistral API\nSomething happened in setting up the request. Error message:\n Invalid URL","stack":"TypeError: Invalid URL\n    at new URL (node:internal/url:806:29)\n    at dispatchHttpRequest (/app/node_modules/axios/dist/node/axios.cjs:2770:20)\n    at /app/node_modules/axios/dist/node/axios.cjs:2690:5\n    at new Promise (<anonymous>)\n    at wrapAsync (/app/node_modules/axios/dist/node/axios.cjs:2670:10)\n    at http (/app/node_modules/axios/dist/node/axios.cjs:2708:10)\n    at Axios.dispatchRequest (/app/node_modules/axios/dist/node/axios.cjs:4135:10)\n    at Axios._request (/app/node_modules/axios/dist/node/axios.cjs:4415:33)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4282:25)\n    at Axios.httpMethod [as post] (/app/node_modules/axios/dist/node/axios.cjs:4454:19)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4287:41)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4287:41)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async fetchModels (/app/api/server/services/ModelService.js:84:17)\n    at async Promise.all (index 0)\n    at async loadConfigModels (/app/api/server/services/Config/loadConfigModels.js:95:23)\n    at async loadModels (/app/api/server/controllers/ModelController.js:30:30)\n    at async modelController (/app/api/server/controllers/ModelController.js:39:23)"}
{"code":"ERR_INVALID_URL","input":"/api/auth/refresh","level":"error","message":"Failed to fetch models from Portkey API\nSomething happened in setting up the request. Error message:\n Invalid URL","stack":"TypeError: Invalid URL\n    at new URL (node:internal/url:806:29)\n    at dispatchHttpRequest (/app/node_modules/axios/dist/node/axios.cjs:2770:20)\n    at /app/node_modules/axios/dist/node/axios.cjs:2690:5\n    at new Promise (<anonymous>)\n    at wrapAsync (/app/node_modules/axios/dist/node/axios.cjs:2670:10)\n    at http (/app/node_modules/axios/dist/node/axios.cjs:2708:10)\n    at Axios.dispatchRequest (/app/node_modules/axios/dist/node/axios.cjs:4135:10)\n    at Axios._request (/app/node_modules/axios/dist/node/axios.cjs:4415:33)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4282:25)\n    at Axios.httpMethod [as post] (/app/node_modules/axios/dist/node/axios.cjs:4454:19)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4287:41)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4287:41)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async fetchModels (/app/api/server/services/ModelService.js:84:17)\n    at async Promise.all (index 2)\n    at async loadConfigModels (/app/api/server/services/Config/loadConfigModels.js:95:23)\n    at async loadModels (/app/api/server/controllers/ModelController.js:30:30)\n    at async modelController (/app/api/server/controllers/ModelController.js:39:23)"}
{"code":-1,"level":"error","message":"[MCP][filesystem] Connection failed: MCP error -1: Connection closed","stack":"Error: MCP error -1: Connection closed\n    at Yr._onclose (file:///app/packages/mcp/dist/index.es.js:1:67087)\n    at _transport.onclose (file:///app/packages/mcp/dist/index.es.js:1:66692)\n    at ChildProcess.<anonymous> (file:///app/packages/mcp/dist/index.es.js:1:78353)\n    at ChildProcess.emit (node:events:518:28)\n    at maybeClose (node:internal/child_process:1104:16)\n    at ChildProcess._handle.onexit (node:internal/child_process:304:5)"}
{"code":-1,"level":"error","message":"[MCP][filesystem] Connection failed: MCP error -1: Connection closed","stack":"Error: MCP error -1: Connection closed\n    at Yr._onclose (file:///app/packages/mcp/dist/index.es.js:1:67087)\n    at _transport.onclose (file:///app/packages/mcp/dist/index.es.js:1:66692)\n    at ChildProcess.<anonymous> (file:///app/packages/mcp/dist/index.es.js:1:78353)\n    at ChildProcess.emit (node:events:518:28)\n    at maybeClose (node:internal/child_process:1104:16)\n    at ChildProcess._handle.onexit (node:internal/child_process:304:5)"}
{"code":-1,"level":"error","message":"[MCP][filesystem] Connection failed: MCP error -1: Connection closed","stack":"Error: MCP error -1: Connection closed\n    at Yr._onclose (file:///app/packages/mcp/dist/index.es.js:1:67087)\n    at _transport.onclose (file:///app/packages/mcp/dist/index.es.js:1:66692)\n    at ChildProcess.<anonymous> (file:///app/packages/mcp/dist/index.es.js:1:78353)\n    at ChildProcess.emit (node:events:518:28)\n    at maybeClose (node:internal/child_process:1104:16)\n    at ChildProcess._handle.onexit (node:internal/child_process:304:5)"}
{"level":"error","message":"[MCP][filesystem] Failed after 3 attempts"}
{"code":-1,"level":"error","message":"[MCP][filesystem] Initialization failed MCP error -1: Connection closed","stack":"Error: MCP error -1: Connection closed\n    at Yr._onclose (file:///app/packages/mcp/dist/index.es.js:1:67087)\n    at _transport.onclose (file:///app/packages/mcp/dist/index.es.js:1:66692)\n    at ChildProcess.<anonymous> (file:///app/packages/mcp/dist/index.es.js:1:78353)\n    at ChildProcess.emit (node:events:518:28)\n    at maybeClose (node:internal/child_process:1104:16)\n    at ChildProcess._handle.onexit (node:internal/child_process:304:5)"}
{"level":"error","message":"[MCP] No servers initialized"}
{"code":"ERR_INVALID_URL","input":"/api/auth/refresh","level":"error","message":"Failed to fetch models from Mistral API\nSomething happened in setting up the request. Error message:\n Invalid URL","stack":"TypeError: Invalid URL\n    at new URL (node:internal/url:806:29)\n    at dispatchHttpRequest (/app/node_modules/axios/dist/node/axios.cjs:2770:20)\n    at /app/node_modules/axios/dist/node/axios.cjs:2690:5\n    at new Promise (<anonymous>)\n    at wrapAsync (/app/node_modules/axios/dist/node/axios.cjs:2670:10)\n    at http (/app/node_modules/axios/dist/node/axios.cjs:2708:10)\n    at Axios.dispatchRequest (/app/node_modules/axios/dist/node/axios.cjs:4135:10)\n    at Axios._request (/app/node_modules/axios/dist/node/axios.cjs:4415:33)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4282:25)\n    at Axios.httpMethod [as post] (/app/node_modules/axios/dist/node/axios.cjs:4454:19)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4287:41)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4287:41)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async fetchModels (/app/api/server/services/ModelService.js:84:17)\n    at async Promise.all (index 0)\n    at async loadConfigModels (/app/api/server/services/Config/loadConfigModels.js:95:23)\n    at async loadModels (/app/api/server/controllers/ModelController.js:30:30)\n    at async modelController (/app/api/server/controllers/ModelController.js:39:23)"}
{"code":"ERR_INVALID_URL","input":"/api/auth/refresh","level":"error","message":"Failed to fetch models from Portkey API\nSomething happened in setting up the request. Error message:\n Invalid URL","stack":"TypeError: Invalid URL\n    at new URL (node:internal/url:806:29)\n    at dispatchHttpRequest (/app/node_modules/axios/dist/node/axios.cjs:2770:20)\n    at /app/node_modules/axios/dist/node/axios.cjs:2690:5\n    at new Promise (<anonymous>)\n    at wrapAsync (/app/node_modules/axios/dist/node/axios.cjs:2670:10)\n    at http (/app/node_modules/axios/dist/node/axios.cjs:2708:10)\n    at Axios.dispatchRequest (/app/node_modules/axios/dist/node/axios.cjs:4135:10)\n    at Axios._request (/app/node_modules/axios/dist/node/axios.cjs:4415:33)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4282:25)\n    at Axios.httpMethod [as post] (/app/node_modules/axios/dist/node/axios.cjs:4454:19)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4287:41)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4287:41)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async fetchModels (/app/api/server/services/ModelService.js:84:17)\n    at async Promise.all (index 2)\n    at async loadConfigModels (/app/api/server/services/Config/loadConfigModels.js:95:23)\n    at async loadModels (/app/api/server/controllers/ModelController.js:30:30)\n    at async modelController (/app/api/server/controllers/ModelController.js:39:23)"}
{"code":"ENOENT","errno":-2,"level":"error","message":"[MCP][filesssystem] Connection failed: spawn python ENOENT","path":"python","spawnargs":["C:/Users/vaibhavarduino/Documents/Python_Scripts/Auto-GPT-Actuallyworks/freegpt/gpt4free/opengpt+/docker-opengpt/python_backend/tests.py"],"stack":"Error: spawn python ENOENT\n    at ChildProcess._handle.onexit (node:internal/child_process:285:19)\n    at onErrorNT (node:internal/child_process:483:16)\n    at process.processTicksAndRejections (node:internal/process/task_queues:82:21)","syscall":"spawn python"}
{"code":"ENOENT","errno":-2,"level":"error","message":"[MCP][filesssystem] Connection failed: spawn python ENOENT","path":"python","spawnargs":["C:/Users/vaibhavarduino/Documents/Python_Scripts/Auto-GPT-Actuallyworks/freegpt/gpt4free/opengpt+/docker-opengpt/python_backend/tests.py"],"stack":"Error: spawn python ENOENT\n    at ChildProcess._handle.onexit (node:internal/child_process:285:19)\n    at onErrorNT (node:internal/child_process:483:16)\n    at process.processTicksAndRejections (node:internal/process/task_queues:82:21)","syscall":"spawn python"}
{"code":"ENOENT","errno":-2,"level":"error","message":"[MCP][filesssystem] Connection failed: spawn python ENOENT","path":"python","spawnargs":["C:/Users/vaibhavarduino/Documents/Python_Scripts/Auto-GPT-Actuallyworks/freegpt/gpt4free/opengpt+/docker-opengpt/python_backend/tests.py"],"stack":"Error: spawn python ENOENT\n    at ChildProcess._handle.onexit (node:internal/child_process:285:19)\n    at onErrorNT (node:internal/child_process:483:16)\n    at process.processTicksAndRejections (node:internal/process/task_queues:82:21)","syscall":"spawn python"}
{"level":"error","message":"[MCP][filesssystem] Failed after 3 attempts"}
{"code":"ENOENT","errno":-2,"level":"error","message":"[MCP][filesssystem] Initialization failed spawn python ENOENT","path":"python","spawnargs":["C:/Users/vaibhavarduino/Documents/Python_Scripts/Auto-GPT-Actuallyworks/freegpt/gpt4free/opengpt+/docker-opengpt/python_backend/tests.py"],"stack":"Error: spawn python ENOENT\n    at ChildProcess._handle.onexit (node:internal/child_process:285:19)\n    at onErrorNT (node:internal/child_process:483:16)\n    at process.processTicksAndRejections (node:internal/process/task_queues:82:21)","syscall":"spawn python"}
{"level":"error","message":"[MCP] No servers initialized"}
{"level":"error","message":"[MCP][everything] Connection failed: SSE error: {}","stack":"Error: SSE error: {}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.scheduleReconnect_fn (/app/node_modules/eventsource/dist/index.cjs:194:53)\n    at /app/node_modules/eventsource/dist/index.cjs:47:174\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP][everything] Connection failed: SSE error: {}","stack":"Error: SSE error: {}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.scheduleReconnect_fn (/app/node_modules/eventsource/dist/index.cjs:194:53)\n    at /app/node_modules/eventsource/dist/index.cjs:47:174\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP][everything] Connection failed: SSE error: {}","stack":"Error: SSE error: {}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.scheduleReconnect_fn (/app/node_modules/eventsource/dist/index.cjs:194:53)\n    at /app/node_modules/eventsource/dist/index.cjs:47:174\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP][everything] Failed after 3 attempts"}
{"level":"error","message":"[MCP][everything] Initialization failed SSE error: {}","stack":"Error: SSE error: {}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.scheduleReconnect_fn (/app/node_modules/eventsource/dist/index.cjs:194:53)\n    at /app/node_modules/eventsource/dist/index.cjs:47:174\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP] No servers initialized"}
{"level":"error","message":"[MCP][everything] Connection failed: SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}","stack":"Error: SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.failConnection_fn (/app/node_modules/eventsource/dist/index.cjs:182:105)\n    at /app/node_modules/eventsource/dist/index.cjs:25:74\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP][everything] Connection failed: SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}","stack":"Error: SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.failConnection_fn (/app/node_modules/eventsource/dist/index.cjs:182:105)\n    at /app/node_modules/eventsource/dist/index.cjs:25:74\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP][everything] Connection failed: SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}","stack":"Error: SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.failConnection_fn (/app/node_modules/eventsource/dist/index.cjs:182:105)\n    at /app/node_modules/eventsource/dist/index.cjs:25:74\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP][everything] Failed after 3 attempts"}
{"level":"error","message":"[MCP][everything] Initialization failed SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}","stack":"Error: SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.failConnection_fn (/app/node_modules/eventsource/dist/index.cjs:182:105)\n    at /app/node_modules/eventsource/dist/index.cjs:25:74\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP] No servers initialized"}
{"level":"error","message":"[MCP][everything] Connection failed: SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}","stack":"Error: SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.failConnection_fn (/app/node_modules/eventsource/dist/index.cjs:182:105)\n    at /app/node_modules/eventsource/dist/index.cjs:25:74\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP][everything] Connection failed: SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}","stack":"Error: SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.failConnection_fn (/app/node_modules/eventsource/dist/index.cjs:182:105)\n    at /app/node_modules/eventsource/dist/index.cjs:25:74\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP][everything] Connection failed: SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}","stack":"Error: SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.failConnection_fn (/app/node_modules/eventsource/dist/index.cjs:182:105)\n    at /app/node_modules/eventsource/dist/index.cjs:25:74\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP][everything] Failed after 3 attempts"}
{"level":"error","message":"[MCP][everything] Initialization failed SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}","stack":"Error: SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.failConnection_fn (/app/node_modules/eventsource/dist/index.cjs:182:105)\n    at /app/node_modules/eventsource/dist/index.cjs:25:74\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP] No servers initialized"}
{"level":"error","message":"[MCP][everything] Connection failed: SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}","stack":"Error: SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.failConnection_fn (/app/node_modules/eventsource/dist/index.cjs:182:105)\n    at /app/node_modules/eventsource/dist/index.cjs:25:74\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP][everything] Connection failed: SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}","stack":"Error: SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.failConnection_fn (/app/node_modules/eventsource/dist/index.cjs:182:105)\n    at /app/node_modules/eventsource/dist/index.cjs:25:74\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP][everything] Connection failed: SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}","stack":"Error: SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.failConnection_fn (/app/node_modules/eventsource/dist/index.cjs:182:105)\n    at /app/node_modules/eventsource/dist/index.cjs:25:74\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP][everything] Failed after 3 attempts"}
{"level":"error","message":"[MCP][everything] Initialization failed SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}","stack":"Error: SSE error: {\"code\":500,\"message\":\"Non-200 status code (500)\"}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.failConnection_fn (/app/node_modules/eventsource/dist/index.cjs:182:105)\n    at /app/node_modules/eventsource/dist/index.cjs:25:74\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP] No servers initialized"}
{"level":"error","message":"[MCP][everything] Connection failed: SSE error: {\"code\":200,\"message\":\"Invalid content type, expected \\\"text/event-stream\\\"\"}","stack":"Error: SSE error: {\"code\":200,\"message\":\"Invalid content type, expected \\\"text/event-stream\\\"\"}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.failConnection_fn (/app/node_modules/eventsource/dist/index.cjs:182:105)\n    at /app/node_modules/eventsource/dist/index.cjs:29:74\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP][everything] Connection failed: SSE error: {\"code\":200,\"message\":\"Invalid content type, expected \\\"text/event-stream\\\"\"}","stack":"Error: SSE error: {\"code\":200,\"message\":\"Invalid content type, expected \\\"text/event-stream\\\"\"}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.failConnection_fn (/app/node_modules/eventsource/dist/index.cjs:182:105)\n    at /app/node_modules/eventsource/dist/index.cjs:29:74\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP][everything] Connection failed: SSE error: {\"code\":200,\"message\":\"Invalid content type, expected \\\"text/event-stream\\\"\"}","stack":"Error: SSE error: {\"code\":200,\"message\":\"Invalid content type, expected \\\"text/event-stream\\\"\"}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.failConnection_fn (/app/node_modules/eventsource/dist/index.cjs:182:105)\n    at /app/node_modules/eventsource/dist/index.cjs:29:74\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP][everything] Failed after 3 attempts"}
{"level":"error","message":"[MCP][everything] Initialization failed SSE error: {\"code\":200,\"message\":\"Invalid content type, expected \\\"text/event-stream\\\"\"}","stack":"Error: SSE error: {\"code\":200,\"message\":\"Invalid content type, expected \\\"text/event-stream\\\"\"}\n    at _eventSource.onerror (file:///app/packages/mcp/dist/index.es.js:1:75382)\n    at EventSource.failConnection_fn (/app/node_modules/eventsource/dist/index.cjs:182:105)\n    at /app/node_modules/eventsource/dist/index.cjs:29:74\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)"}
{"level":"error","message":"[MCP] No servers initialized"}
{"code":"ENOENT","errno":-2,"level":"error","message":"[MCP][filesssystem] Connection failed: spawn python ENOENT","path":"python","spawnargs":["C:/Users/vaibhavarduino/Documents/Python_Scripts/Auto-GPT-Actuallyworks/freegpt/gpt4free/opengpt+/docker-opengpt/python_backend/tests.py"],"stack":"Error: spawn python ENOENT\n    at ChildProcess._handle.onexit (node:internal/child_process:285:19)\n    at onErrorNT (node:internal/child_process:483:16)\n    at process.processTicksAndRejections (node:internal/process/task_queues:82:21)","syscall":"spawn python"}
{"code":"ENOENT","errno":-2,"level":"error","message":"[MCP][filesssystem] Connection failed: spawn python ENOENT","path":"python","spawnargs":["C:/Users/vaibhavarduino/Documents/Python_Scripts/Auto-GPT-Actuallyworks/freegpt/gpt4free/opengpt+/docker-opengpt/python_backend/tests.py"],"stack":"Error: spawn python ENOENT\n    at ChildProcess._handle.onexit (node:internal/child_process:285:19)\n    at onErrorNT (node:internal/child_process:483:16)\n    at process.processTicksAndRejections (node:internal/process/task_queues:82:21)","syscall":"spawn python"}
{"code":"ENOENT","errno":-2,"level":"error","message":"[MCP][filesssystem] Connection failed: spawn python ENOENT","path":"python","spawnargs":["C:/Users/vaibhavarduino/Documents/Python_Scripts/Auto-GPT-Actuallyworks/freegpt/gpt4free/opengpt+/docker-opengpt/python_backend/tests.py"],"stack":"Error: spawn python ENOENT\n    at ChildProcess._handle.onexit (node:internal/child_process:285:19)\n    at onErrorNT (node:internal/child_process:483:16)\n    at process.processTicksAndRejections (node:internal/process/task_queues:82:21)","syscall":"spawn python"}
{"code":"ENOENT","errno":-2,"level":"error","message":"[MCP][filesssystem] Connection failed: spawn python ENOENT","path":"python","spawnargs":["C:/Users/vaibhavarduino/Documents/Python_Scripts/Auto-GPT-Actuallyworks/freegpt/gpt4free/opengpt+/docker-opengpt/python_backend/tests.py"],"stack":"Error: spawn python ENOENT\n    at ChildProcess._handle.onexit (node:internal/child_process:285:19)\n    at onErrorNT (node:internal/child_process:483:16)\n    at process.processTicksAndRejections (node:internal/process/task_queues:82:21)","syscall":"spawn python"}
{"code":-1,"level":"error","message":"[MCP][filesssystem] Connection failed: MCP error -1: Connection closed","stack":"Error: MCP error -1: Connection closed\n    at Yr._onclose (file:///app/packages/mcp/dist/index.es.js:1:67087)\n    at _transport.onclose (file:///app/packages/mcp/dist/index.es.js:1:66692)\n    at ChildProcess.<anonymous> (file:///app/packages/mcp/dist/index.es.js:1:78353)\n    at ChildProcess.emit (node:events:518:28)\n    at maybeClose (node:internal/child_process:1104:16)\n    at ChildProcess._handle.onexit (node:internal/child_process:304:5)"}
{"code":-1,"level":"error","message":"[MCP][filesssystem] Connection failed: MCP error -1: Connection closed","stack":"Error: MCP error -1: Connection closed\n    at Yr._onclose (file:///app/packages/mcp/dist/index.es.js:1:67087)\n    at _transport.onclose (file:///app/packages/mcp/dist/index.es.js:1:66692)\n    at ChildProcess.<anonymous> (file:///app/packages/mcp/dist/index.es.js:1:78353)\n    at ChildProcess.emit (node:events:518:28)\n    at maybeClose (node:internal/child_process:1104:16)\n    at ChildProcess._handle.onexit (node:internal/child_process:304:5)"}
{"code":-1,"level":"error","message":"[MCP][filesssystem] Connection failed: MCP error -1: Connection closed","stack":"Error: MCP error -1: Connection closed\n    at Yr._onclose (file:///app/packages/mcp/dist/index.es.js:1:67087)\n    at _transport.onclose (file:///app/packages/mcp/dist/index.es.js:1:66692)\n    at ChildProcess.<anonymous> (file:///app/packages/mcp/dist/index.es.js:1:78353)\n    at ChildProcess.emit (node:events:518:28)\n    at maybeClose (node:internal/child_process:1104:16)\n    at ChildProcess._handle.onexit (node:internal/child_process:304:5)"}
{"level":"error","message":"[MCP][filesssystem] Failed after 3 attempts"}
{"code":-1,"level":"error","message":"[MCP][filesssystem] Initialization failed MCP error -1: Connection closed","stack":"Error: MCP error -1: Connection closed\n    at Yr._onclose (file:///app/packages/mcp/dist/index.es.js:1:67087)\n    at _transport.onclose (file:///app/packages/mcp/dist/index.es.js:1:66692)\n    at ChildProcess.<anonymous> (file:///app/packages/mcp/dist/index.es.js:1:78353)\n    at ChildProcess.emit (node:events:518:28)\n    at maybeClose (node:internal/child_process:1104:16)\n    at ChildProcess._handle.onexit (node:internal/child_process:304:5)"}
{"level":"error","message":"[MCP] No servers initialized"}
{"code":"ERR_INVALID_URL","input":"/api/auth/refresh","level":"error","message":"Failed to fetch models from Mistral API\nSomething happened in setting up the request. Error message:\n Invalid URL","stack":"TypeError: Invalid URL\n    at new URL (node:internal/url:806:29)\n    at dispatchHttpRequest (/app/node_modules/axios/dist/node/axios.cjs:2770:20)\n    at /app/node_modules/axios/dist/node/axios.cjs:2690:5\n    at new Promise (<anonymous>)\n    at wrapAsync (/app/node_modules/axios/dist/node/axios.cjs:2670:10)\n    at http (/app/node_modules/axios/dist/node/axios.cjs:2708:10)\n    at Axios.dispatchRequest (/app/node_modules/axios/dist/node/axios.cjs:4135:10)\n    at Axios._request (/app/node_modules/axios/dist/node/axios.cjs:4415:33)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4282:25)\n    at Axios.httpMethod [as post] (/app/node_modules/axios/dist/node/axios.cjs:4454:19)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4287:41)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4287:41)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async fetchModels (/app/api/server/services/ModelService.js:84:17)\n    at async Promise.all (index 0)\n    at async loadConfigModels (/app/api/server/services/Config/loadConfigModels.js:95:23)\n    at async loadModels (/app/api/server/controllers/ModelController.js:30:30)\n    at async modelController (/app/api/server/controllers/ModelController.js:39:23)"}
{"code":"ERR_INVALID_URL","input":"/api/auth/refresh","level":"error","message":"Failed to fetch models from Portkey API\nSomething happened in setting up the request. Error message:\n Invalid URL","stack":"TypeError: Invalid URL\n    at new URL (node:internal/url:806:29)\n    at dispatchHttpRequest (/app/node_modules/axios/dist/node/axios.cjs:2770:20)\n    at /app/node_modules/axios/dist/node/axios.cjs:2690:5\n    at new Promise (<anonymous>)\n    at wrapAsync (/app/node_modules/axios/dist/node/axios.cjs:2670:10)\n    at http (/app/node_modules/axios/dist/node/axios.cjs:2708:10)\n    at Axios.dispatchRequest (/app/node_modules/axios/dist/node/axios.cjs:4135:10)\n    at Axios._request (/app/node_modules/axios/dist/node/axios.cjs:4415:33)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4282:25)\n    at Axios.httpMethod [as post] (/app/node_modules/axios/dist/node/axios.cjs:4454:19)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4287:41)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4287:41)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async fetchModels (/app/api/server/services/ModelService.js:84:17)\n    at async Promise.all (index 2)\n    at async loadConfigModels (/app/api/server/services/Config/loadConfigModels.js:95:23)\n    at async loadModels (/app/api/server/controllers/ModelController.js:30:30)\n    at async modelController (/app/api/server/controllers/ModelController.js:39:23)"}
{"code":"ERR_INVALID_URL","input":"/api/auth/refresh","level":"error","message":"Failed to fetch models from Mistral API\nSomething happened in setting up the request. Error message:\n Invalid URL","stack":"TypeError: Invalid URL\n    at new URL (node:internal/url:806:29)\n    at dispatchHttpRequest (/app/node_modules/axios/dist/node/axios.cjs:2770:20)\n    at /app/node_modules/axios/dist/node/axios.cjs:2690:5\n    at new Promise (<anonymous>)\n    at wrapAsync (/app/node_modules/axios/dist/node/axios.cjs:2670:10)\n    at http (/app/node_modules/axios/dist/node/axios.cjs:2708:10)\n    at Axios.dispatchRequest (/app/node_modules/axios/dist/node/axios.cjs:4135:10)\n    at Axios._request (/app/node_modules/axios/dist/node/axios.cjs:4415:33)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4282:25)\n    at Axios.httpMethod [as post] (/app/node_modules/axios/dist/node/axios.cjs:4454:19)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4287:41)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4287:41)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async fetchModels (/app/api/server/services/ModelService.js:84:17)\n    at async Promise.all (index 0)\n    at async loadConfigModels (/app/api/server/services/Config/loadConfigModels.js:95:23)\n    at async loadModels (/app/api/server/controllers/ModelController.js:30:30)\n    at async modelController (/app/api/server/controllers/ModelController.js:39:23)"}
{"code":"ERR_INVALID_URL","input":"/api/auth/refresh","level":"error","message":"Failed to fetch models from Portkey API\nSomething happened in setting up the request. Error message:\n Invalid URL","stack":"TypeError: Invalid URL\n    at new URL (node:internal/url:806:29)\n    at dispatchHttpRequest (/app/node_modules/axios/dist/node/axios.cjs:2770:20)\n    at /app/node_modules/axios/dist/node/axios.cjs:2690:5\n    at new Promise (<anonymous>)\n    at wrapAsync (/app/node_modules/axios/dist/node/axios.cjs:2670:10)\n    at http (/app/node_modules/axios/dist/node/axios.cjs:2708:10)\n    at Axios.dispatchRequest (/app/node_modules/axios/dist/node/axios.cjs:4135:10)\n    at Axios._request (/app/node_modules/axios/dist/node/axios.cjs:4415:33)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4282:25)\n    at Axios.httpMethod [as post] (/app/node_modules/axios/dist/node/axios.cjs:4454:19)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4287:41)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at Axios.request (/app/node_modules/axios/dist/node/axios.cjs:4287:41)\n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\n    at async fetchModels (/app/api/server/services/ModelService.js:84:17)\n    at async Promise.all (index 2)\n    at async loadConfigModels (/app/api/server/services/Config/loadConfigModels.js:95:23)\n    at async loadModels (/app/api/server/controllers/ModelController.js:30:30)\n    at async modelController (/app/api/server/controllers/ModelController.js:39:23)"}
